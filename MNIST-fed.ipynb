{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated Learning Test\n",
    "\n",
    "This notebook is a test of federated learning using the MNIST dataset. It distributes partial subsets of the MNIST data to each worker and tests the results of federation of the workers. It also skews the subsets to investigate the value of federation in cases where workers have substantially different samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Baseline\n",
    "\n",
    "First, we load up the common elements to be used in the traditional and federated approaches. We start with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class MLPNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLPNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 500)\n",
    "        self.fc2 = nn.Linear(500, 256)\n",
    "        self.fc3 = nn.Linear(256, 10)\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = nn.functional.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def name(self):\n",
    "        return \"MLP\"\n",
    "\n",
    "# # Optional model for fun\n",
    "\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# class LeNet(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(LeNet, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "#         self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "#         self.conv2_drop = nn.Dropout2d()\n",
    "#         self.fc1 = nn.Linear(320, 50)\n",
    "#         self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "#         x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "#         x = x.view(-1, 320)\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = F.dropout(x, training=self.training)\n",
    "#         x = self.fc2(x)\n",
    "#         return F.log_softmax(x, dim=0) # value 0 was chosen arbitrarily to quiet a warning. Penny'll start a fire.\n",
    "\n",
    "#     def name(self):\n",
    "#         return 'LeNet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "\n",
    "import torch\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# create standard datasets using all of the MNIST data\n",
    "\n",
    "data_path = './MNIST-data/raw'\n",
    "trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])\n",
    "\n",
    "train_dset = dsets.MNIST(root=data_path, download=True, train=True, transform=trans)\n",
    "test_dset = dsets.MNIST(root=data_path, download=True, train=False, transform=trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking a Deck\n",
    "\n",
    "We need a way to \"stack the deck\" of examples that each worker sees. This method creates a dataset that is randomly sampled from a given dataset with the random sampling biased according to a dictionary of weights for each label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "def stacked_dset(dset, label_weights, N):\n",
    "    \"\"\"\n",
    "    dset: dataset\n",
    "    label_weights = {dog: 0.5, cat: 0.3, ...}\n",
    "    N: size of stacked dset\n",
    "    return: stacked WeightedRandomSampler\n",
    "    \"\"\"\n",
    "    weights = []\n",
    "    for data, label in dset:\n",
    "        weights.append(label_weights[label])\n",
    "    return WeightedRandomSampler(weights, N, replacement=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this is where we get the dictionary of weights. For simplicity's sake, we just take a list of labels to be sampled \"normally\" and the rest are biased against. So, preserving 3s and skewing everything else by a factor of 0.9 shoud get a set of weights that results in a dataset that is slightly heavy on 3s compared to everything else. In an an extreme example, preserving only 3s, with a skew of 0, will produce weights that will yield a dataset of only 3s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skewed_weights(num_labels, labels_to_preserve, skew_bias):\n",
    "    \"\"\"\n",
    "        num_labels: number of labels to return (use 10 for MNIST)\n",
    "        labels_to_preserve: list of labels to preserve wih no skew \n",
    "        skew_bias: a float, 0 < bias < 1, to which non-selected labels will be biased down\n",
    "        return: dictionary of each label and its bias\n",
    "    \"\"\"\n",
    "    weights = {}\n",
    "    for label in range(num_labels):\n",
    "        if label in labels_to_preserve:\n",
    "            weights[label] = 1\n",
    "        else:\n",
    "            weights[label] = skew_bias\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# # create standard dataloaders using all of the MNIST data - this is for baseline purposes\n",
    "train_dloader = DataLoader(train_dset, batch_size=batch_size, shuffle=True)\n",
    "test_dloader = DataLoader(test_dset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:  [(1, 1135), (2, 1032), (7, 1028), (3, 1010), (9, 1009), (4, 982), (0, 980), (8, 974), (6, 958), (5, 892)]\n",
      "Train: [(1, 6742), (7, 6265), (3, 6131), (2, 5958), (9, 5949), (0, 5923), (6, 5918), (8, 5851), (4, 5842), (5, 5421)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "_, ys = list(zip(*test_dloader))\n",
    "print(\"Test: \", Counter(int(y) for y in torch.cat(ys)).most_common())\n",
    "\n",
    "_, ys = list(zip(*train_dloader))\n",
    "print(\"Train:\", Counter(int(y) for y in torch.cat(ys)).most_common())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These plots show quickly that the sets are distributed fairly similarly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "fig.suptitle('Testing examples')\n",
    "ax.xaxis.set_major_locator(plt.MultipleLocator(1))\n",
    "H = ax.hist(test_dloader.dataset.targets, bins=range(11), histtype='bar', align='left', rwidth=0.8)\n",
    "plt.show();\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "fig.suptitle('Training examples')\n",
    "ax.xaxis.set_major_locator(plt.MultipleLocator(1))\n",
    "H = ax.hist(train_dloader.dataset.targets, bins=range(11), histtype='bar', align='left', rwidth=0.8)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we do the sampling to create our skewed datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:26<00:00,  8.57s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# create stacked loaders for the workers\n",
    "\n",
    "skew_bias = 0.5\n",
    "loader_size = 2048\n",
    "num_workers = 2\n",
    "\n",
    "stacked_data_loaders = []\n",
    "\n",
    "for label in tqdm(range(num_workers)):\n",
    "    stacked_sampler = stacked_dset(train_dset, skewed_weights(10, [label], skew_bias), loader_size)\n",
    "    stacked_data_loaders.append(DataLoader(train_dset, batch_size=batch_size, shuffle=False, sampler=stacked_sampler))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should see the effect of the skew in a histogram of a skewed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:  [(1, 425), (7, 209), (2, 190), (6, 184), (9, 184), (3, 183), (8, 174), (5, 172), (4, 167), (0, 160)]\n"
     ]
    }
   ],
   "source": [
    "_, ys = list(zip(*stacked_data_loaders[1]))\n",
    "print(\"Test: \", Counter(int(y) for y in torch.cat(ys)).most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "fig.suptitle('Skew examples')\n",
    "ax.xaxis.set_major_locator(plt.MultipleLocator(1))\n",
    "H = ax.hist(stacked_data_loaders[1].dataset.targets, bins=range(11), histtype='bar', align='left', rwidth=0.8)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import federated\n",
    "\n",
    "learning_rate = 5e-3\n",
    "num_epochs = 1\n",
    "num_rounds = 5\n",
    "\n",
    "skewed_train_dsets = stacked_data_loaders\n",
    "\n",
    "manager = federated.FederatedManager(\n",
    "    skewed_train_dsets,\n",
    "    MLPNet,\n",
    "    nn.CrossEntropyLoss(),\n",
    "    learning_rate,\n",
    "    test_dset,\n",
    "    num_epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 5 round(s) with 10 worker(s) doing 1 epoch(s) each\n",
      "\n",
      "Beginning round 1\n",
      "\tWorker: 5904 \tepoch: 1 \tbatch: 0 \tlocal loss: 2.2971\n",
      "\tWorker: 5904 \tepoch: 1 \tbatch: 8 \tlocal loss: 2.3001\n",
      "\tWorker: 5904 \tepoch: 1 \tbatch: 16 \tlocal loss: 2.2853\n",
      "\tWorker: 5904 \tepoch: 1 \tbatch: 24 \tlocal loss: 2.2821\n",
      "\tWorker: 5904 \tepoch: 1 \tbatch: 32 \tlocal loss: 2.2649 \n",
      "\n",
      "\tWorker: 7768 \tepoch: 1 \tbatch: 0 \tlocal loss: 2.3065\n",
      "\tWorker: 7768 \tepoch: 1 \tbatch: 8 \tlocal loss: 2.2967\n",
      "\tWorker: 7768 \tepoch: 1 \tbatch: 16 \tlocal loss: 2.2934\n",
      "\tWorker: 7768 \tepoch: 1 \tbatch: 24 \tlocal loss: 2.2960\n",
      "\tWorker: 7768 \tepoch: 1 \tbatch: 32 \tlocal loss: 2.2950 \n",
      "\n",
      "\tWorker: 3368 \tepoch: 1 \tbatch: 0 \tlocal loss: 2.3282\n",
      "\tWorker: 3368 \tepoch: 1 \tbatch: 8 \tlocal loss: 2.3048\n",
      "\tWorker: 3368 \tepoch: 1 \tbatch: 16 \tlocal loss: 2.3048\n",
      "\tWorker: 3368 \tepoch: 1 \tbatch: 24 \tlocal loss: 2.3191\n",
      "\tWorker: 3368 \tepoch: 1 \tbatch: 32 \tlocal loss: 2.3094 \n",
      "\n",
      "\tWorker: 1856 \tepoch: 1 \tbatch: 0 \tlocal loss: 2.3004\n",
      "\tWorker: 1856 \tepoch: 1 \tbatch: 8 \tlocal loss: 2.2906\n",
      "\tWorker: 1856 \tepoch: 1 \tbatch: 16 \tlocal loss: 2.2977\n",
      "\tWorker: 1856 \tepoch: 1 \tbatch: 24 \tlocal loss: 2.2797\n",
      "\tWorker: 1856 \tepoch: 1 \tbatch: 32 \tlocal loss: 2.2870 \n",
      "\n",
      "\tWorker: 5984 \tepoch: 1 \tbatch: 0 \tlocal loss: 2.3065\n",
      "\tWorker: 5984 \tepoch: 1 \tbatch: 8 \tlocal loss: 2.3056\n",
      "\tWorker: 5984 \tepoch: 1 \tbatch: 16 \tlocal loss: 2.2803\n",
      "\tWorker: 5984 \tepoch: 1 \tbatch: 24 \tlocal loss: 2.2903\n",
      "\tWorker: 5984 \tepoch: 1 \tbatch: 32 \tlocal loss: 2.2982 \n",
      "\n",
      "\tWorker: 6752 \tepoch: 1 \tbatch: 0 \tlocal loss: 2.3137\n",
      "\tWorker: 6752 \tepoch: 1 \tbatch: 8 \tlocal loss: 2.3054\n",
      "\tWorker: 6752 \tepoch: 1 \tbatch: 16 \tlocal loss: 2.3027\n",
      "\tWorker: 6752 \tepoch: 1 \tbatch: 24 \tlocal loss: 2.2976\n",
      "\tWorker: 6752 \tepoch: 1 \tbatch: 32 \tlocal loss: 2.3060 \n",
      "\n",
      "\tWorker: 6360 \tepoch: 1 \tbatch: 0 \tlocal loss: 2.2989\n",
      "\tWorker: 6360 \tepoch: 1 \tbatch: 8 \tlocal loss: 2.3116\n",
      "\tWorker: 6360 \tepoch: 1 \tbatch: 16 \tlocal loss: 2.2913\n",
      "\tWorker: 6360 \tepoch: 1 \tbatch: 24 \tlocal loss: 2.2996\n",
      "\tWorker: 6360 \tepoch: 1 \tbatch: 32 \tlocal loss: 2.2871 \n",
      "\n",
      "\tWorker: 7584 \tepoch: 1 \tbatch: 0 \tlocal loss: 2.2994\n",
      "\tWorker: 7584 \tepoch: 1 \tbatch: 8 \tlocal loss: 2.2853\n",
      "\tWorker: 7584 \tepoch: 1 \tbatch: 16 \tlocal loss: 2.2842\n",
      "\tWorker: 7584 \tepoch: 1 \tbatch: 24 \tlocal loss: 2.2765\n",
      "\tWorker: 7584 \tepoch: 1 \tbatch: 32 \tlocal loss: 2.2873 \n",
      "\n",
      "\tWorker: 4296 \tepoch: 1 \tbatch: 0 \tlocal loss: 2.3123\n",
      "\tWorker: 4296 \tepoch: 1 \tbatch: 8 \tlocal loss: 2.3133\n",
      "\tWorker: 4296 \tepoch: 1 \tbatch: 16 \tlocal loss: 2.2926\n",
      "\tWorker: 4296 \tepoch: 1 \tbatch: 24 \tlocal loss: 2.2831\n",
      "\tWorker: 4296 \tepoch: 1 \tbatch: 32 \tlocal loss: 2.2901 \n",
      "\n",
      "\tWorker: 4352 \tepoch: 1 \tbatch: 0 \tlocal loss: 2.3008\n",
      "\tWorker: 4352 \tepoch: 1 \tbatch: 8 \tlocal loss: 2.3014\n",
      "\tWorker: 4352 \tepoch: 1 \tbatch: 16 \tlocal loss: 2.3020\n",
      "\tWorker: 4352 \tepoch: 1 \tbatch: 24 \tlocal loss: 2.3042\n",
      "\tWorker: 4352 \tepoch: 1 \tbatch: 32 \tlocal loss: 2.3008 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 1/5 [00:38<02:33, 38.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 1 with global loss: 2.29564 \n",
      "\n",
      "Beginning round 2\n",
      "\tWorker: 5904 \tepoch: 1 \tbatch: 0 \tlocal loss: 2.3064\n",
      "\tWorker: 5904 \tepoch: 1 \tbatch: 8 \tlocal loss: 2.2888\n",
      "\tWorker: 5904 \tepoch: 1 \tbatch: 16 \tlocal loss: 2.2759\n",
      "\tWorker: 5904 \tepoch: 1 \tbatch: 24 \tlocal loss: 2.2592\n",
      "\tWorker: 5904 \tepoch: 1 \tbatch: 32 \tlocal loss: 2.2626 \n",
      "\n",
      "\tWorker: 7768 \tepoch: 1 \tbatch: 0 \tlocal loss: 2.3090\n",
      "\tWorker: 7768 \tepoch: 1 \tbatch: 8 \tlocal loss: 2.2947\n",
      "\tWorker: 7768 \tepoch: 1 \tbatch: 16 \tlocal loss: 2.2924\n",
      "\tWorker: 7768 \tepoch: 1 \tbatch: 24 \tlocal loss: 2.2649\n",
      "\tWorker: 7768 \tepoch: 1 \tbatch: 32 \tlocal loss: 2.2772 \n",
      "\n",
      "\tWorker: 3368 \tepoch: 1 \tbatch: 0 \tlocal loss: 2.3036\n",
      "\tWorker: 3368 \tepoch: 1 \tbatch: 8 \tlocal loss: 2.3049\n",
      "\tWorker: 3368 \tepoch: 1 \tbatch: 16 \tlocal loss: 2.2953\n",
      "\tWorker: 3368 \tepoch: 1 \tbatch: 24 \tlocal loss: 2.2856\n",
      "\tWorker: 3368 \tepoch: 1 \tbatch: 32 \tlocal loss: 2.2879 \n",
      "\n",
      "\tWorker: 1856 \tepoch: 1 \tbatch: 0 \tlocal loss: 2.2979\n",
      "\tWorker: 1856 \tepoch: 1 \tbatch: 8 \tlocal loss: 2.2756\n",
      "\tWorker: 1856 \tepoch: 1 \tbatch: 16 \tlocal loss: 2.2814\n",
      "\tWorker: 1856 \tepoch: 1 \tbatch: 24 \tlocal loss: 2.2598\n",
      "\tWorker: 1856 \tepoch: 1 \tbatch: 32 \tlocal loss: 2.2719 \n",
      "\n",
      "\tWorker: 5984 \tepoch: 1 \tbatch: 0 \tlocal loss: 2.2793\n",
      "\tWorker: 5984 \tepoch: 1 \tbatch: 8 \tlocal loss: 2.2818\n",
      "\tWorker: 5984 \tepoch: 1 \tbatch: 16 \tlocal loss: 2.2848\n",
      "\tWorker: 5984 \tepoch: 1 \tbatch: 24 \tlocal loss: 2.2804\n",
      "\tWorker: 5984 \tepoch: 1 \tbatch: 32 \tlocal loss: 2.2871 \n",
      "\n",
      "\tWorker: 6752 \tepoch: 1 \tbatch: 0 \tlocal loss: 2.3032\n",
      "\tWorker: 6752 \tepoch: 1 \tbatch: 8 \tlocal loss: 2.2844\n",
      "\tWorker: 6752 \tepoch: 1 \tbatch: 16 \tlocal loss: 2.2842\n",
      "\tWorker: 6752 \tepoch: 1 \tbatch: 24 \tlocal loss: 2.2784\n",
      "\tWorker: 6752 \tepoch: 1 \tbatch: 32 \tlocal loss: 2.2877 \n",
      "\n",
      "\tWorker: 6360 \tepoch: 1 \tbatch: 0 \tlocal loss: 2.2966\n",
      "\tWorker: 6360 \tepoch: 1 \tbatch: 8 \tlocal loss: 2.2679\n",
      "\tWorker: 6360 \tepoch: 1 \tbatch: 16 \tlocal loss: 2.2879\n",
      "\tWorker: 6360 \tepoch: 1 \tbatch: 24 \tlocal loss: 2.2746\n",
      "\tWorker: 6360 \tepoch: 1 \tbatch: 32 \tlocal loss: 2.2750 \n",
      "\n",
      "\tWorker: 7584 \tepoch: 1 \tbatch: 0 \tlocal loss: 2.2953\n",
      "\tWorker: 7584 \tepoch: 1 \tbatch: 8 \tlocal loss: 2.2602\n",
      "\tWorker: 7584 \tepoch: 1 \tbatch: 16 \tlocal loss: 2.2759\n",
      "\tWorker: 7584 \tepoch: 1 \tbatch: 24 \tlocal loss: 2.2714\n",
      "\tWorker: 7584 \tepoch: 1 \tbatch: 32 \tlocal loss: 2.2942 \n",
      "\n",
      "\tWorker: 4296 \tepoch: 1 \tbatch: 0 \tlocal loss: 2.2976\n",
      "\tWorker: 4296 \tepoch: 1 \tbatch: 8 \tlocal loss: 2.2827\n",
      "\tWorker: 4296 \tepoch: 1 \tbatch: 16 \tlocal loss: 2.2897\n",
      "\tWorker: 4296 \tepoch: 1 \tbatch: 24 \tlocal loss: 2.2712\n",
      "\tWorker: 4296 \tepoch: 1 \tbatch: 32 \tlocal loss: 2.2669 \n",
      "\n",
      "\tWorker: 4352 \tepoch: 1 \tbatch: 0 \tlocal loss: 2.3182\n",
      "\tWorker: 4352 \tepoch: 1 \tbatch: 8 \tlocal loss: 2.3145\n",
      "\tWorker: 4352 \tepoch: 1 \tbatch: 16 \tlocal loss: 2.2838\n",
      "\tWorker: 4352 \tepoch: 1 \tbatch: 24 \tlocal loss: 2.2888\n",
      "\tWorker: 4352 \tepoch: 1 \tbatch: 32 \tlocal loss: 2.2759 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 2/5 [01:13<01:52, 37.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 2 with global loss: 2.28360 \n",
      "\n",
      "Beginning round 3\n",
      "\tWorker: 5904 \tepoch: 1 \tbatch: 0 \tlocal loss: 2.2721\n",
      "\tWorker: 5904 \tepoch: 1 \tbatch: 8 \tlocal loss: 2.2740\n",
      "\tWorker: 5904 \tepoch: 1 \tbatch: 16 \tlocal loss: 2.2796\n",
      "\tWorker: 5904 \tepoch: 1 \tbatch: 24 \tlocal loss: 2.2585\n",
      "\tWorker: 5904 \tepoch: 1 \tbatch: 32 \tlocal loss: 2.2651 \n",
      "\n",
      "\tWorker: 7768 \tepoch: 1 \tbatch: 0 \tlocal loss: 2.2807\n",
      "\tWorker: 7768 \tepoch: 1 \tbatch: 8 \tlocal loss: 2.2738\n",
      "\tWorker: 7768 \tepoch: 1 \tbatch: 16 \tlocal loss: 2.2648\n",
      "\tWorker: 7768 \tepoch: 1 \tbatch: 24 \tlocal loss: 2.2423\n",
      "\tWorker: 7768 \tepoch: 1 \tbatch: 32 \tlocal loss: 2.2591 \n",
      "\n",
      "\tWorker: 3368 \tepoch: 1 \tbatch: 0 \tlocal loss: 2.2894\n",
      "\tWorker: 3368 \tepoch: 1 \tbatch: 8 \tlocal loss: 2.2948\n",
      "\tWorker: 3368 \tepoch: 1 \tbatch: 16 \tlocal loss: 2.2886\n",
      "\tWorker: 3368 \tepoch: 1 \tbatch: 24 \tlocal loss: 2.2847\n",
      "\tWorker: 3368 \tepoch: 1 \tbatch: 32 \tlocal loss: 2.2782 \n",
      "\n",
      "\tWorker: 1856 \tepoch: 1 \tbatch: 0 \tlocal loss: 2.2657\n",
      "\tWorker: 1856 \tepoch: 1 \tbatch: 8 \tlocal loss: 2.2685\n",
      "\tWorker: 1856 \tepoch: 1 \tbatch: 16 \tlocal loss: 2.2686\n",
      "\tWorker: 1856 \tepoch: 1 \tbatch: 24 \tlocal loss: 2.2616\n",
      "\tWorker: 1856 \tepoch: 1 \tbatch: 32 \tlocal loss: 2.2513 \n",
      "\n",
      "\tWorker: 5984 \tepoch: 1 \tbatch: 0 \tlocal loss: 2.2780\n",
      "\tWorker: 5984 \tepoch: 1 \tbatch: 8 \tlocal loss: 2.2662\n",
      "\tWorker: 5984 \tepoch: 1 \tbatch: 16 \tlocal loss: 2.2664\n",
      "\tWorker: 5984 \tepoch: 1 \tbatch: 24 \tlocal loss: 2.2666\n",
      "\tWorker: 5984 \tepoch: 1 \tbatch: 32 \tlocal loss: 2.2525 \n",
      "\n",
      "\tWorker: 6752 \tepoch: 1 \tbatch: 0 \tlocal loss: 2.2806\n",
      "\tWorker: 6752 \tepoch: 1 \tbatch: 8 \tlocal loss: 2.2816\n",
      "\tWorker: 6752 \tepoch: 1 \tbatch: 16 \tlocal loss: 2.2929\n",
      "\tWorker: 6752 \tepoch: 1 \tbatch: 24 \tlocal loss: 2.2706\n",
      "\tWorker: 6752 \tepoch: 1 \tbatch: 32 \tlocal loss: 2.2842 \n",
      "\n",
      "\tWorker: 6360 \tepoch: 1 \tbatch: 0 \tlocal loss: 2.2750\n",
      "\tWorker: 6360 \tepoch: 1 \tbatch: 8 \tlocal loss: 2.2617\n",
      "\tWorker: 6360 \tepoch: 1 \tbatch: 16 \tlocal loss: 2.2697\n",
      "\tWorker: 6360 \tepoch: 1 \tbatch: 24 \tlocal loss: 2.2620\n",
      "\tWorker: 6360 \tepoch: 1 \tbatch: 32 \tlocal loss: 2.2517 \n",
      "\n",
      "\tWorker: 7584 \tepoch: 1 \tbatch: 0 \tlocal loss: 2.2830\n",
      "\tWorker: 7584 \tepoch: 1 \tbatch: 8 \tlocal loss: 2.2696\n",
      "\tWorker: 7584 \tepoch: 1 \tbatch: 16 \tlocal loss: 2.2582\n",
      "\tWorker: 7584 \tepoch: 1 \tbatch: 24 \tlocal loss: 2.2632\n",
      "\tWorker: 7584 \tepoch: 1 \tbatch: 32 \tlocal loss: 2.2806 \n",
      "\n",
      "\tWorker: 4296 \tepoch: 1 \tbatch: 0 \tlocal loss: 2.2687\n",
      "\tWorker: 4296 \tepoch: 1 \tbatch: 8 \tlocal loss: 2.2851\n",
      "\tWorker: 4296 \tepoch: 1 \tbatch: 16 \tlocal loss: 2.2717\n",
      "\tWorker: 4296 \tepoch: 1 \tbatch: 24 \tlocal loss: 2.2808\n",
      "\tWorker: 4296 \tepoch: 1 \tbatch: 32 \tlocal loss: 2.2697 \n",
      "\n",
      "\tWorker: 4352 \tepoch: 1 \tbatch: 0 \tlocal loss: 2.2890\n",
      "\tWorker: 4352 \tepoch: 1 \tbatch: 8 \tlocal loss: 2.2851\n",
      "\tWorker: 4352 \tepoch: 1 \tbatch: 16 \tlocal loss: 2.2789\n",
      "\tWorker: 4352 \tepoch: 1 \tbatch: 24 \tlocal loss: 2.2713\n",
      "\tWorker: 4352 \tepoch: 1 \tbatch: 32 \tlocal loss: 2.2679 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 3/5 [01:52<01:15, 37.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 3 with global loss: 2.27214 \n",
      "\n",
      "Beginning round 4\n",
      "\tWorker: 5904 \tepoch: 1 \tbatch: 0 \tlocal loss: 2.2668\n",
      "\tWorker: 5904 \tepoch: 1 \tbatch: 8 \tlocal loss: 2.2834\n",
      "\tWorker: 5904 \tepoch: 1 \tbatch: 16 \tlocal loss: 2.2761\n",
      "\tWorker: 5904 \tepoch: 1 \tbatch: 24 \tlocal loss: 2.2659\n",
      "\tWorker: 5904 \tepoch: 1 \tbatch: 32 \tlocal loss: 2.2676 \n",
      "\n",
      "\tWorker: 7768 \tepoch: 1 \tbatch: 0 \tlocal loss: 2.2748\n",
      "\tWorker: 7768 \tepoch: 1 \tbatch: 8 \tlocal loss: 2.2474\n",
      "\tWorker: 7768 \tepoch: 1 \tbatch: 16 \tlocal loss: 2.2671\n",
      "\tWorker: 7768 \tepoch: 1 \tbatch: 24 \tlocal loss: 2.2620\n",
      "\tWorker: 7768 \tepoch: 1 \tbatch: 32 \tlocal loss: 2.2308 \n",
      "\n",
      "\tWorker: 3368 \tepoch: 1 \tbatch: 0 \tlocal loss: 2.2801\n",
      "\tWorker: 3368 \tepoch: 1 \tbatch: 8 \tlocal loss: 2.2709\n",
      "\tWorker: 3368 \tepoch: 1 \tbatch: 16 \tlocal loss: 2.2663\n",
      "\tWorker: 3368 \tepoch: 1 \tbatch: 24 \tlocal loss: 2.2667\n",
      "\tWorker: 3368 \tepoch: 1 \tbatch: 32 \tlocal loss: 2.2564 \n",
      "\n",
      "\tWorker: 1856 \tepoch: 1 \tbatch: 0 \tlocal loss: 2.2549\n",
      "\tWorker: 1856 \tepoch: 1 \tbatch: 8 \tlocal loss: 2.2532\n",
      "\tWorker: 1856 \tepoch: 1 \tbatch: 16 \tlocal loss: 2.2516\n",
      "\tWorker: 1856 \tepoch: 1 \tbatch: 24 \tlocal loss: 2.2609\n",
      "\tWorker: 1856 \tepoch: 1 \tbatch: 32 \tlocal loss: 2.2406 \n",
      "\n",
      "\tWorker: 5984 \tepoch: 1 \tbatch: 0 \tlocal loss: 2.2641\n",
      "\tWorker: 5984 \tepoch: 1 \tbatch: 8 \tlocal loss: 2.2739\n",
      "\tWorker: 5984 \tepoch: 1 \tbatch: 16 \tlocal loss: 2.2583\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-a36cd70f84a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_rounds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Beginning round\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Finished round\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"with global loss: %.5f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanager_loss_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/bfpytorch/federated.py\u001b[0m in \u001b[0;36mround\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mweighted\u001b[0m \u001b[0maverage\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdo\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreceive\u001b[0m \u001b[0ma\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mserver\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \"\"\"\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfedavg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparticipant\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/bfpytorch/federated.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mweighted\u001b[0m \u001b[0maverage\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdo\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreceive\u001b[0m \u001b[0ma\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mserver\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \"\"\"\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfedavg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparticipant\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/bfpytorch/federated.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m                 \u001b[0mypred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m                 \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mypred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                 \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/bfpytorch/venv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-236b4c674d57>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/bfpytorch/venv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/bfpytorch/venv/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/bfpytorch/venv/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1352\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unwrap_optional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1353\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Training\", num_rounds, \"round(s) with\", manager.n_workers, \"worker(s) doing\", num_epochs, \"epoch(s) each\\n\" )\n",
    "\n",
    "for i in tqdm(range(num_rounds)):\n",
    "    print(\"Beginning round\", i+1)\n",
    "    manager.round()\n",
    "    print(\"Finished round\", i+1, \"with global loss: %.5f\" % manager.manager_loss_history[-1], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "# loss of global model on test set gets recorded twice per round\n",
    "# [1::2] skips the record that takes place before that round's training has happened\n",
    "ax.plot(manager.manager_loss_history[1::2], label=\"Global Loss\")\n",
    "ax.set_xlabel(\"Round\");\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "for i in range(len(manager.worker_loss_histories)):\n",
    "    lbl = \"Worker \" + str(i)\n",
    "    ax.plot(manager.worker_loss_histories[i], label=lbl)\n",
    "    ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outline:\n",
    "- Set up a model and data\n",
    "- train the model N epochs without federation note baseline performance (and size of the data that would have to have been transferedd?) \n",
    "    - is this model trained on the full dataset? Or do we sample randomly across it to have the same number of examples?\n",
    "- Federate without skew or mild skew, compare performance with baseline (and size of model compared to data)\n",
    "- Federate with only a few numbers skewed (like, lacking only 7s or something) \n",
    "- Federate with heavy skew\n",
    "- Federate with complete skew\n",
    "\n",
    "Ideas:\n",
    "- plot performance on a given numeral for the main model next to that of a worker skewed against that numeral. Let both run without federation or run a few epochs before federation. Show this as a baseline\n",
    "- histogram of numerals? More for curiosity, but shows spread of data that we might want to reflect in the baseline training.\n",
    "- why use ten workers? Why not fewer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
