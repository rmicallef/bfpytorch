{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated Machine Learning in PyTorch\n",
    "\n",
    "This notebook is a demonstration of _federated learning_, a type of machine learning in which a machine learning task is addressed using multiple devices, implemented in `pytorch`, a python implementation of the `torch` machine learning framework. This notebook is part of a series intended to start from the basics to demonstrate federated learning in pytorch, then move on to test some of the bounds of what federated learning can (and can't) do.\n",
    "\n",
    "Now, let's talk about what we're going to see in _this_ notebook.\n",
    "\n",
    "## The Task: Digit Recognition\n",
    "\n",
    "For this demonstration, our task is a classic one: the MNIST digit recognition task. Specifically, we need to determine which number is written in an image of a handwritten digit like this one: \n",
    "\n",
    "![Handwritten digit \"6\"](images/example-6.png)\n",
    "\n",
    "To carry out this task we need a machine learning model to \"look\" at an image and classify it into a number. We also need and image data to train the model. We're going to use a simple convolutional neural network model. For the training images, we're using the well-known MNIST digits dataset.\n",
    "\n",
    "## The Approach: Federation\n",
    "\n",
    "The federated approach uses several _worker_ devices to train their own local models with independent data. That is, the workers each train their own local model with a subset of the full dataset.\n",
    "\n",
    "Each worker trains its local model for a bit, then sends its incrementally trained local model back to a _manager_. The manager combines the local models from all of the workers into a master model, then sends the master model back to the workers. This process is called a _round_. \n",
    "\n",
    "Then another round begins: the workers each train their local copy of the master model (creating another set of individualized local models), send those local models back to the manager. Once again the manager combines these individualized local models into a new master model, and pushes the new master model down to the workers. This cycle of rounds repeats as long as is necessary and useful.\n",
    "\n",
    "## Our Federation Library\n",
    "\n",
    "The `federated` library we're using here includes a `FederatedManager` class and a `FederatedWorker` class. A `FederatedManager` contains a master prediction model and creates several independent `FederatedWorker` instances. Each `FederatedWorker` has its own local model and a distinct subset of the MNIST data.\n",
    "\n",
    "In each `round` of federated learning, each `FederatedWorker` trains its local model using only the data that that worker recieves, and then sends its trained local model to the `FederatedManager`. The `FederatedManager` combines the models into an updated master model and pushes that new master model down to each `FederatedWorker`.\n",
    "\n",
    "We're going to see how federation works and test out some corner cases here. Let's get started with the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Basics\n",
    "\n",
    "We need to load up the common elements to be used in the traditional and federated machine learning approaches. But we do a little housekeeping first to track performance of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "run_data = {} # used for code profiling\n",
    "\n",
    "run_data['Date'] = datetime.datetime.today().strftime('%Y-%m-%d %H:%M:%S')\n",
    "run_data['Global Start Time'] = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Model\n",
    "\n",
    "Now we define the model. We're using a simple multilayer perceptron in the `torch` framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class MLPNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLPNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 500)\n",
    "        self.fc2 = nn.Linear(500, 256)\n",
    "        self.fc3 = nn.Linear(256, 10)\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = nn.functional.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Data - Standard MNIST Datasets\n",
    "Here we get plain vanilla MNIST data, a training set and a test set. Nothing exciting to see here. This is our baseline. \n",
    "\n",
    "If you don't already have the MNIST data on your machine, the setting `download=True` in the call to `torchvision.datasets.MNIST()` will fetch the data for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "\n",
    "import torch\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# create standard datasets using all of the MNIST data\n",
    "\n",
    "data_path = './MNIST-data/raw'\n",
    "trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])\n",
    "\n",
    "train_dset = dsets.MNIST(root=data_path, download=True, train=True, transform=trans)\n",
    "test_dset = dsets.MNIST(root=data_path, download=True, train=False, transform=trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have our standard MNIST datasets: `train_dset` contains 60,000 examples, and `test_dset` contains 10,000 samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: EXPLAIN WHY WE NORMALIZE THE DATA, AND WHY WE USE THOSE VALUES?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloaders\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "run_data['Batch Size'] = batch_size = 256\n",
    "\n",
    "# create standard dataloaders using all of the MNIST data - this is for baseline purposes\n",
    "train_dloader = DataLoader(train_dset, batch_size=batch_size, shuffle=True)\n",
    "test_dloader = DataLoader(test_dset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out the default data. The out-of-the-box MNIST dataset has roughly equal numbers of samples for each digit, i.e., about as many `4`s as `6`s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training data is reasonably well distributed, and the plots below confirm it. We scaled up the test set counts by a factor of six to make them comparable to the training set, which has exactly six times as many examples as the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "fig.suptitle('Standard MNIST Digit Counts')\n",
    "ax.xaxis.set_major_locator(plt.MultipleLocator(1))\n",
    "ax.hist([train_dloader.dataset.targets.tolist(), test_dloader.dataset.targets.tolist()*6], \n",
    "        label=['Train', 'Test (scaled)'],\n",
    "        bins=list(range(11)), \n",
    "        histtype='bar',\n",
    "        align='left',\n",
    "        rwidth=0.8,\n",
    "       )\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline: The Non-Federated Approach\n",
    "\n",
    "To show a baseline of non-federated learning, we train a model using just one worker (we're technically using the federated library, but with one worker, it's equivalent to non-federated learning). This one worker will train on the full standard MNIST dataset of 60,000 examples.\n",
    "\n",
    "TODO: AND THEN DO WE WANT TO SHOW A MODEL TRAINED ONLY ON ONE SKEWED DATASET?\n",
    "\n",
    "TODO: Explain (and apologize?) the hack to measure the length of a dataset? Or find another way?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size:  60000\n"
     ]
    }
   ],
   "source": [
    "import federated\n",
    "\n",
    "run_data['Learning Rate'] = learning_rate = 1e-2\n",
    "run_data['Epochs per Round'] = num_epochs = 1\n",
    "run_data['Nonfederated Training Rounds'] = num_rounds = 3\n",
    "\n",
    "default_manager = federated.FederatedManager(\n",
    "    [train_dloader],\n",
    "    MLPNet,\n",
    "    nn.CrossEntropyLoss(),\n",
    "    learning_rate,\n",
    "    test_dset,\n",
    "    num_epochs\n",
    ")\n",
    "\n",
    "print(\"Dataset size: \", len(train_dloader.dataset))\n",
    "    \n",
    "#_, ybatches = list(zip(*train_dloader))\n",
    "#print(\"Dataset size:\", len(torch.cat(ybatches)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 3 round(s) with 1 worker(s) doing 1 epoch(s) per round.\n",
      "\n",
      "Beginning round 1\n",
      "\tWorker: 7112 \tlocal loss: 2.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 1/3 [00:32<01:04, 32.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 1 with global loss: 2.07815 \n",
      "\n",
      "Beginning round 2\n",
      "\tWorker: 7112 \tlocal loss: 1.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 2/3 [01:00<00:31, 31.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 2 with global loss: 1.40588 \n",
      "\n",
      "Beginning round 3\n",
      "\tWorker: 7112 \tlocal loss: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 3/3 [01:32<00:00, 31.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 3 with global loss: 0.85352 \n",
      "\n",
      "Federated Training Time: 92.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "print(\"Training\", num_rounds, \"round(s) with\", default_manager.n_workers, \"worker(s) doing\", num_epochs, \"epoch(s) per round.\\n\" )\n",
    "\n",
    "training_start_time = time.time()\n",
    "\n",
    "for i in tqdm(range(num_rounds)):\n",
    "    print(\"Beginning round\", i+1)\n",
    "    default_manager.round()\n",
    "    print(\"Finished round\", i+1, \"with global loss: %.5f\" % default_manager.manager_loss_history[-1], \"\\n\")\n",
    "\n",
    "run_data['Federated Training Time'] = time.time() - training_start_time\n",
    "#run_data['Manager Loss History'] = default_manager.manager_loss_history\n",
    "#run_data['Worker Loss Histories'] = default_manager.worker_loss_histories\n",
    "run_data['Final Global Loss'] = default_manager.manager_loss_history[-1]\n",
    "\n",
    "print('Federated Training Time: %.2f' % run_data['Federated Training Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig_default, ax_default = plt.subplots(figsize=(16, 9))\n",
    "# loss of global model on test set gets recorded twice per round\n",
    "# [1::2] skips the record that takes place before that round's training has happened\n",
    "ax_default.plot(default_manager.manager_loss_history[1::2], label=\"Global Loss\", )\n",
    "ax_default.set_xlabel(\"Federated Round\")\n",
    "ax_default.set_ylabel(\"Loss\")\n",
    "ax_default.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Federated Approach\n",
    "\n",
    "TODO: Federated learning _without_ the skew?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unskewed Federated?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking the Deck (Skewing Data)\n",
    "\n",
    "We know the baseline data is pretty even across numerals. Now we need a way to \"stack the deck\" of examples that each worker sees. This method creates a dataset that is randomly sampled from a given dataset with the random sampling biased according to a dictionary of weights for each label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "def stacked_dset(dset, label_weights, N):\n",
    "    \"\"\"\n",
    "        dset: dataset\n",
    "        label_weights = {dog: 0.5, cat: 0.3, ...}\n",
    "        N: size of stacked dset\n",
    "        return: stacked WeightedRandomSampler\n",
    "    \"\"\"\n",
    "    weights = []\n",
    "    for data, label in dset:\n",
    "        weights.append(label_weights[label])\n",
    "\n",
    "#     for label in test_dset.targets:\n",
    "#         weights.append(label_weights[int(label)])\n",
    "# TODO / MLW : how to speed this up - currently takes about a minute to train ten stacked training sets\n",
    "    \n",
    "    return WeightedRandomSampler(weights, N, replacement=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this is where we get the dictionary of weights. For simplicity's sake, we just take a list of labels to be sampled \"normally\" and the rest are biased against. So, preserving `3`s and skewing everything else by a factor of 0.9 shoud get a set of weights that results in a dataset that is slightly heavy on `3`s compared to everything else. In an an extreme example, preserving only `3`s, with a skew of 0, will produce weights that will yield a dataset of only `3`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skewed_weights(num_labels, labels_to_preserve, skew_bias):\n",
    "    \"\"\"\n",
    "        num_labels: number of labels to return (use 10 for MNIST)\n",
    "        labels_to_preserve: list of labels to preserve wih no skew \n",
    "        skew_bias: a float, 0 < bias < 1, to which non-selected labels will be biased down\n",
    "        return: dictionary of each label and its bias\n",
    "    \"\"\"\n",
    "    weights = {}\n",
    "    for label in range(num_labels):\n",
    "        if label in labels_to_preserve:\n",
    "            weights[label] = 1\n",
    "        else:\n",
    "            weights[label] = skew_bias\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we do the sampling to create our skewed datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:55<00:00, 17.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Time: 175.44\n",
      "Stacking Time per Loader: 17.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# create stacked loaders for the workers\n",
    "\n",
    "run_data['Skew Bias'] = skew_bias = 0.05\n",
    "run_data['Examples Per Skewed Loader'] = loader_size = 1000\n",
    "run_data['Number of Workers'] = num_workers = 10\n",
    "\n",
    "stacking_start_time = time.time()\n",
    "\n",
    "stacked_data_loaders = []\n",
    "for label in tqdm(range(num_workers)):\n",
    "    stacked_sampler = stacked_dset(train_dset, skewed_weights(10, [label%10], skew_bias), loader_size)\n",
    "    stacked_data_loaders.append(DataLoader(train_dset, batch_size=batch_size, shuffle=False, sampler=stacked_sampler))\n",
    "\n",
    "run_data['Stacking Time'] = time.time() - stacking_start_time\n",
    "run_data['Stacking Time per Loader'] = run_data['Stacking Time'] / run_data['Number of Workers']\n",
    "\n",
    "print('Stacking Time: %.2f' % run_data['Stacking Time'])\n",
    "print('Stacking Time per Loader: %.2f' % run_data['Stacking Time per Loader'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should see the effect of the skew in a count and histogram of a skewed dataset. Here, we arbitrarily picked the first dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader sample count: 600\n"
     ]
    }
   ],
   "source": [
    "_, ybatches = list(zip(*stacked_data_loaders[0]))\n",
    "print('Dataloader sample count:', len(torch.cat(ybatches)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader 0 sample count: 600\n",
      "Dataloader 1 sample count: 600\n",
      "Dataloader 2 sample count: 600\n",
      "Dataloader 3 sample count: 600\n",
      "Dataloader 4 sample count: 600\n",
      "Dataloader 5 sample count: 600\n",
      "Dataloader 6 sample count: 600\n",
      "Dataloader 7 sample count: 600\n",
      "Dataloader 8 sample count: 600\n",
      "Dataloader 9 sample count: 600\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(stacked_data_loaders)):\n",
    "    _, ybatches = list(zip(*stacked_data_loaders[i]))\n",
    "    print('Dataloader', i ,'sample count:', len(torch.cat(ybatches)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:01<00:09,  1.10s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(405, 20, 19, 28, 27, 20, 20, 20, 20, 21)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 2/10 [00:02<00:09,  1.15s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 446, 14, 14, 25, 13, 23, 21, 18, 14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 3/10 [00:04<00:09,  1.37s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 23, 391, 20, 27, 17, 23, 32, 24, 19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 4/10 [00:05<00:08,  1.47s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 26, 12, 411, 24, 15, 25, 20, 27, 19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 5/10 [00:08<00:08,  1.71s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 26, 18, 27, 392, 13, 35, 24, 21, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 6/10 [00:09<00:06,  1.72s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 18, 20, 22, 22, 401, 23, 22, 30, 24)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|███████   | 7/10 [00:11<00:05,  1.76s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 23, 20, 32, 22, 14, 400, 18, 23, 24)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 8/10 [00:13<00:03,  1.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 36, 14, 17, 19, 28, 19, 406, 15, 26)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████ | 9/10 [00:14<00:01,  1.46s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 18, 17, 23, 14, 24, 28, 400, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 10/10 [00:15<00:00,  1.32s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23, 19, 18, 25, 17, 20, 22, 35, 17, 404)\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "hist_counts = []\n",
    "digit_counts = []\n",
    "for loader in tqdm(stacked_data_loaders):\n",
    "    _, ybatches = list(zip(*loader))\n",
    "    ys = torch.cat(ybatches)\n",
    "    ys = [int(y) for y in ys]\n",
    "    hist_counts.append(ys)\n",
    "    \n",
    "    digits = sorted(Counter(ys).most_common())\n",
    "    _, digits = list(zip(*digits))\n",
    "    print(digits)\n",
    "    #print(loader)\n",
    "    digit_counts.append(list(digits))\n",
    "\n",
    "digit_counts = [list(i) for i in zip(*digit_counts)]\n",
    "\n",
    "print(len(digit_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   [405, 12, 24, 21, 24, 18, 24, 20, 28, 23],\n",
      "    [20, 446, 23, 26, 26, 18, 23, 36, 28, 19],\n",
      "    [19, 14, 391, 12, 18, 20, 20, 14, 18, 18],\n",
      "    [28, 14, 20, 411, 27, 22, 32, 17, 17, 25],\n",
      "    [27, 25, 27, 24, 392, 22, 22, 19, 23, 17],\n",
      "    [20, 13, 17, 15, 13, 401, 14, 28, 14, 20],\n",
      "    [20, 23, 23, 25, 35, 23, 400, 19, 24, 22],\n",
      "    [20, 21, 32, 20, 24, 22, 18, 406, 28, 35],\n",
      "    [20, 18, 24, 27, 21, 30, 23, 15, 400, 17],\n",
      "    [21, 14, 19, 19, 20, 24, 24, 26, 20, 404]]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "pp.pprint(digit_counts)\n",
    "#print(hist_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "fig.suptitle('Skew Example')\n",
    "ax.xaxis.set_major_locator(plt.MultipleLocator(1))\n",
    "H = ax.hist(hist_counts, bins=range(11), histtype='bar', align='left', rwidth=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "fig.suptitle('Skew: Digit Counts by Worker')\n",
    "\n",
    "pos = list(range(num_workers))\n",
    "width = 0.08\n",
    "\n",
    "for digit in range(len(digit_counts)):\n",
    "    #print(digit)\n",
    "    ax.bar([p + (width * digit) for p in pos],\n",
    "           digit_counts[digit],\n",
    "           width = width,\n",
    "           label = str(digit),\n",
    "          )\n",
    "\n",
    "ax.set_xticks([p + (4.5 * width) for p in pos])\n",
    "ax.set_xticklabels([('Worker ' + str(x)) for x in range(num_workers)])\n",
    "ax.set_ylabel('Digit Samples')\n",
    "ax.legend(loc = 'upper right');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the `federatedManager` using the skewed training data. Note that we don't skew the test data -- we want to see how everything performs on a normal data distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import federated\n",
    "\n",
    "run_data['Learning Rate'] = learning_rate = 3e-3\n",
    "run_data['Epochs per Round'] = num_epochs = 1\n",
    "run_data['Federated Training Rounds'] = num_rounds = 100\n",
    "\n",
    "manager = federated.FederatedManager(\n",
    "    stacked_data_loaders,\n",
    "    MLPNet,\n",
    "    nn.CrossEntropyLoss(),\n",
    "    learning_rate,\n",
    "    test_dset,\n",
    "    num_epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do some rounds of federated training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 100 round(s) with 10 worker(s) doing 1 epoch(s) per round.\n",
      "\n",
      "Beginning round 1\n",
      "\tWorker: 6032 \tlocal loss: 2.29\n",
      "\tWorker: 7904 \tlocal loss: 2.33\n",
      "\tWorker: 8440 \tlocal loss: 2.33\n",
      "\tWorker: 5680 \tlocal loss: 2.30\n",
      "\tWorker: 9656 \tlocal loss: 2.25\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.26\n",
      "\tWorker: 9976 \tlocal loss: 2.26\n",
      "\tWorker: 3760 \tlocal loss: 2.26\n",
      "\tWorker: 6616 \tlocal loss: 2.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 1/100 [00:21<36:14, 21.96s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 1 with global loss: 2.31 \n",
      "\n",
      "Beginning round 2\n",
      "\tWorker: 6032 \tlocal loss: 2.30\n",
      "\tWorker: 7904 \tlocal loss: 2.33\n",
      "\tWorker: 8440 \tlocal loss: 2.33\n",
      "\tWorker: 5680 \tlocal loss: 2.30\n",
      "\tWorker: 9656 \tlocal loss: 2.26\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.27\n",
      "\tWorker: 9976 \tlocal loss: 2.28\n",
      "\tWorker: 3760 \tlocal loss: 2.26\n",
      "\tWorker: 6616 \tlocal loss: 2.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▏         | 2/100 [00:48<37:54, 23.21s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 2 with global loss: 2.31 \n",
      "\n",
      "Beginning round 3\n",
      "\tWorker: 6032 \tlocal loss: 2.29\n",
      "\tWorker: 7904 \tlocal loss: 2.33\n",
      "\tWorker: 8440 \tlocal loss: 2.32\n",
      "\tWorker: 5680 \tlocal loss: 2.29\n",
      "\tWorker: 9656 \tlocal loss: 2.25\n",
      "\tWorker: 3888 \tlocal loss: 2.26\n",
      "\tWorker: 1952 \tlocal loss: 2.26\n",
      "\tWorker: 9976 \tlocal loss: 2.27\n",
      "\tWorker: 3760 \tlocal loss: 2.26\n",
      "\tWorker: 6616 \tlocal loss: 2.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  3%|▎         | 3/100 [01:14<38:59, 24.12s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 3 with global loss: 2.31 \n",
      "\n",
      "Beginning round 4\n",
      "\tWorker: 6032 \tlocal loss: 2.29\n",
      "\tWorker: 7904 \tlocal loss: 2.33\n",
      "\tWorker: 8440 \tlocal loss: 2.33\n",
      "\tWorker: 5680 \tlocal loss: 2.29\n",
      "\tWorker: 9656 \tlocal loss: 2.25\n",
      "\tWorker: 3888 \tlocal loss: 2.24\n",
      "\tWorker: 1952 \tlocal loss: 2.26\n",
      "\tWorker: 9976 \tlocal loss: 2.27\n",
      "\tWorker: 3760 \tlocal loss: 2.26\n",
      "\tWorker: 6616 \tlocal loss: 2.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  4%|▍         | 4/100 [01:37<38:04, 23.80s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 4 with global loss: 2.30 \n",
      "\n",
      "Beginning round 5\n",
      "\tWorker: 6032 \tlocal loss: 2.30\n",
      "\tWorker: 7904 \tlocal loss: 2.33\n",
      "\tWorker: 8440 \tlocal loss: 2.32\n",
      "\tWorker: 5680 \tlocal loss: 2.29\n",
      "\tWorker: 9656 \tlocal loss: 2.25\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.25\n",
      "\tWorker: 9976 \tlocal loss: 2.27\n",
      "\tWorker: 3760 \tlocal loss: 2.26\n",
      "\tWorker: 6616 \tlocal loss: 2.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 5/100 [02:00<37:31, 23.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 5 with global loss: 2.30 \n",
      "\n",
      "Beginning round 6\n",
      "\tWorker: 6032 \tlocal loss: 2.29\n",
      "\tWorker: 7904 \tlocal loss: 2.33\n",
      "\tWorker: 8440 \tlocal loss: 2.32\n",
      "\tWorker: 5680 \tlocal loss: 2.29\n",
      "\tWorker: 9656 \tlocal loss: 2.24\n",
      "\tWorker: 3888 \tlocal loss: 2.26\n",
      "\tWorker: 1952 \tlocal loss: 2.28\n",
      "\tWorker: 9976 \tlocal loss: 2.27\n",
      "\tWorker: 3760 \tlocal loss: 2.26\n",
      "\tWorker: 6616 \tlocal loss: 2.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  6%|▌         | 6/100 [02:27<38:22, 24.49s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 6 with global loss: 2.30 \n",
      "\n",
      "Beginning round 7\n",
      "\tWorker: 6032 \tlocal loss: 2.29\n",
      "\tWorker: 7904 \tlocal loss: 2.33\n",
      "\tWorker: 8440 \tlocal loss: 2.31\n",
      "\tWorker: 5680 \tlocal loss: 2.29\n",
      "\tWorker: 9656 \tlocal loss: 2.26\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.25\n",
      "\tWorker: 9976 \tlocal loss: 2.27\n",
      "\tWorker: 3760 \tlocal loss: 2.26\n",
      "\tWorker: 6616 \tlocal loss: 2.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  7%|▋         | 7/100 [02:50<37:12, 24.01s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 7 with global loss: 2.30 \n",
      "\n",
      "Beginning round 8\n",
      "\tWorker: 6032 \tlocal loss: 2.29\n",
      "\tWorker: 7904 \tlocal loss: 2.33\n",
      "\tWorker: 8440 \tlocal loss: 2.33\n",
      "\tWorker: 5680 \tlocal loss: 2.30\n",
      "\tWorker: 9656 \tlocal loss: 2.24\n",
      "\tWorker: 3888 \tlocal loss: 2.26\n",
      "\tWorker: 1952 \tlocal loss: 2.26\n",
      "\tWorker: 9976 \tlocal loss: 2.27\n",
      "\tWorker: 3760 \tlocal loss: 2.27\n",
      "\tWorker: 6616 \tlocal loss: 2.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  8%|▊         | 8/100 [03:17<38:19, 24.99s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 8 with global loss: 2.30 \n",
      "\n",
      "Beginning round 9\n",
      "\tWorker: 6032 \tlocal loss: 2.29\n",
      "\tWorker: 7904 \tlocal loss: 2.32\n",
      "\tWorker: 8440 \tlocal loss: 2.32\n",
      "\tWorker: 5680 \tlocal loss: 2.29\n",
      "\tWorker: 9656 \tlocal loss: 2.24\n",
      "\tWorker: 3888 \tlocal loss: 2.26\n",
      "\tWorker: 1952 \tlocal loss: 2.28\n",
      "\tWorker: 9976 \tlocal loss: 2.26\n",
      "\tWorker: 3760 \tlocal loss: 2.26\n",
      "\tWorker: 6616 \tlocal loss: 2.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  9%|▉         | 9/100 [03:39<36:36, 24.13s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 9 with global loss: 2.30 \n",
      "\n",
      "Beginning round 10\n",
      "\tWorker: 6032 \tlocal loss: 2.29\n",
      "\tWorker: 7904 \tlocal loss: 2.32\n",
      "\tWorker: 8440 \tlocal loss: 2.33\n",
      "\tWorker: 5680 \tlocal loss: 2.28\n",
      "\tWorker: 9656 \tlocal loss: 2.25\n",
      "\tWorker: 3888 \tlocal loss: 2.26\n",
      "\tWorker: 1952 \tlocal loss: 2.26\n",
      "\tWorker: 9976 \tlocal loss: 2.27\n",
      "\tWorker: 3760 \tlocal loss: 2.26\n",
      "\tWorker: 6616 \tlocal loss: 2.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 10/100 [04:03<36:19, 24.21s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 10 with global loss: 2.30 \n",
      "\n",
      "Beginning round 11\n",
      "\tWorker: 6032 \tlocal loss: 2.28\n",
      "\tWorker: 7904 \tlocal loss: 2.32\n",
      "\tWorker: 8440 \tlocal loss: 2.33\n",
      "\tWorker: 5680 \tlocal loss: 2.29\n",
      "\tWorker: 9656 \tlocal loss: 2.24\n",
      "\tWorker: 3888 \tlocal loss: 2.26\n",
      "\tWorker: 1952 \tlocal loss: 2.26\n",
      "\tWorker: 9976 \tlocal loss: 2.27\n",
      "\tWorker: 3760 \tlocal loss: 2.26\n",
      "\tWorker: 6616 \tlocal loss: 2.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 11%|█         | 11/100 [04:29<36:21, 24.51s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 11 with global loss: 2.30 \n",
      "\n",
      "Beginning round 12\n",
      "\tWorker: 6032 \tlocal loss: 2.29\n",
      "\tWorker: 7904 \tlocal loss: 2.32\n",
      "\tWorker: 8440 \tlocal loss: 2.32\n",
      "\tWorker: 5680 \tlocal loss: 2.28\n",
      "\tWorker: 9656 \tlocal loss: 2.24\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.25\n",
      "\tWorker: 9976 \tlocal loss: 2.26\n",
      "\tWorker: 3760 \tlocal loss: 2.26\n",
      "\tWorker: 6616 \tlocal loss: 2.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 12%|█▏        | 12/100 [04:55<36:57, 25.20s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 12 with global loss: 2.30 \n",
      "\n",
      "Beginning round 13\n",
      "\tWorker: 6032 \tlocal loss: 2.29\n",
      "\tWorker: 7904 \tlocal loss: 2.32\n",
      "\tWorker: 8440 \tlocal loss: 2.32\n",
      "\tWorker: 5680 \tlocal loss: 2.29\n",
      "\tWorker: 9656 \tlocal loss: 2.24\n",
      "\tWorker: 3888 \tlocal loss: 2.24\n",
      "\tWorker: 1952 \tlocal loss: 2.26\n",
      "\tWorker: 9976 \tlocal loss: 2.26\n",
      "\tWorker: 3760 \tlocal loss: 2.26\n",
      "\tWorker: 6616 \tlocal loss: 2.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 13%|█▎        | 13/100 [05:22<37:05, 25.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 13 with global loss: 2.30 \n",
      "\n",
      "Beginning round 14\n",
      "\tWorker: 6032 \tlocal loss: 2.29\n",
      "\tWorker: 7904 \tlocal loss: 2.31\n",
      "\tWorker: 8440 \tlocal loss: 2.32\n",
      "\tWorker: 5680 \tlocal loss: 2.28\n",
      "\tWorker: 9656 \tlocal loss: 2.24\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.26\n",
      "\tWorker: 9976 \tlocal loss: 2.25\n",
      "\tWorker: 3760 \tlocal loss: 2.27\n",
      "\tWorker: 6616 \tlocal loss: 2.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 14%|█▍        | 14/100 [05:43<34:47, 24.28s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 14 with global loss: 2.30 \n",
      "\n",
      "Beginning round 15\n",
      "\tWorker: 6032 \tlocal loss: 2.28\n",
      "\tWorker: 7904 \tlocal loss: 2.31\n",
      "\tWorker: 8440 \tlocal loss: 2.31\n",
      "\tWorker: 5680 \tlocal loss: 2.28\n",
      "\tWorker: 9656 \tlocal loss: 2.24\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.25\n",
      "\tWorker: 9976 \tlocal loss: 2.26\n",
      "\tWorker: 3760 \tlocal loss: 2.26\n",
      "\tWorker: 6616 \tlocal loss: 2.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▌        | 15/100 [06:09<35:02, 24.73s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 15 with global loss: 2.30 \n",
      "\n",
      "Beginning round 16\n",
      "\tWorker: 6032 \tlocal loss: 2.29\n",
      "\tWorker: 7904 \tlocal loss: 2.31\n",
      "\tWorker: 8440 \tlocal loss: 2.32\n",
      "\tWorker: 5680 \tlocal loss: 2.28\n",
      "\tWorker: 9656 \tlocal loss: 2.24\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.25\n",
      "\tWorker: 9976 \tlocal loss: 2.26\n",
      "\tWorker: 3760 \tlocal loss: 2.26\n",
      "\tWorker: 6616 \tlocal loss: 2.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 16%|█▌        | 16/100 [06:27<31:51, 22.75s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 16 with global loss: 2.30 \n",
      "\n",
      "Beginning round 17\n",
      "\tWorker: 6032 \tlocal loss: 2.28\n",
      "\tWorker: 7904 \tlocal loss: 2.31\n",
      "\tWorker: 8440 \tlocal loss: 2.32\n",
      "\tWorker: 5680 \tlocal loss: 2.28\n",
      "\tWorker: 9656 \tlocal loss: 2.24\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.26\n",
      "\tWorker: 9976 \tlocal loss: 2.26\n",
      "\tWorker: 3760 \tlocal loss: 2.25\n",
      "\tWorker: 6616 \tlocal loss: 2.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 17%|█▋        | 17/100 [06:45<29:41, 21.46s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 17 with global loss: 2.29 \n",
      "\n",
      "Beginning round 18\n",
      "\tWorker: 6032 \tlocal loss: 2.28\n",
      "\tWorker: 7904 \tlocal loss: 2.30\n",
      "\tWorker: 8440 \tlocal loss: 2.31\n",
      "\tWorker: 5680 \tlocal loss: 2.28\n",
      "\tWorker: 9656 \tlocal loss: 2.24\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.26\n",
      "\tWorker: 9976 \tlocal loss: 2.26\n",
      "\tWorker: 3760 \tlocal loss: 2.26\n",
      "\tWorker: 6616 \tlocal loss: 2.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 18%|█▊        | 18/100 [07:09<30:08, 22.06s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 18 with global loss: 2.29 \n",
      "\n",
      "Beginning round 19\n",
      "\tWorker: 6032 \tlocal loss: 2.28\n",
      "\tWorker: 7904 \tlocal loss: 2.30\n",
      "\tWorker: 8440 \tlocal loss: 2.31\n",
      "\tWorker: 5680 \tlocal loss: 2.28\n",
      "\tWorker: 9656 \tlocal loss: 2.24\n",
      "\tWorker: 3888 \tlocal loss: 2.26\n",
      "\tWorker: 1952 \tlocal loss: 2.26\n",
      "\tWorker: 9976 \tlocal loss: 2.26\n",
      "\tWorker: 3760 \tlocal loss: 2.26\n",
      "\tWorker: 6616 \tlocal loss: 2.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 19%|█▉        | 19/100 [07:25<27:20, 20.26s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 19 with global loss: 2.29 \n",
      "\n",
      "Beginning round 20\n",
      "\tWorker: 6032 \tlocal loss: 2.29\n",
      "\tWorker: 7904 \tlocal loss: 2.30\n",
      "\tWorker: 8440 \tlocal loss: 2.31\n",
      "\tWorker: 5680 \tlocal loss: 2.28\n",
      "\tWorker: 9656 \tlocal loss: 2.24\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.26\n",
      "\tWorker: 9976 \tlocal loss: 2.26\n",
      "\tWorker: 3760 \tlocal loss: 2.26\n",
      "\tWorker: 6616 \tlocal loss: 2.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 20/100 [07:43<25:57, 19.47s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 20 with global loss: 2.29 \n",
      "\n",
      "Beginning round 21\n",
      "\tWorker: 6032 \tlocal loss: 2.28\n",
      "\tWorker: 7904 \tlocal loss: 2.29\n",
      "\tWorker: 8440 \tlocal loss: 2.32\n",
      "\tWorker: 5680 \tlocal loss: 2.28\n",
      "\tWorker: 9656 \tlocal loss: 2.25\n",
      "\tWorker: 3888 \tlocal loss: 2.26\n",
      "\tWorker: 1952 \tlocal loss: 2.27\n",
      "\tWorker: 9976 \tlocal loss: 2.25\n",
      "\tWorker: 3760 \tlocal loss: 2.26\n",
      "\tWorker: 6616 \tlocal loss: 2.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 21%|██        | 21/100 [08:04<26:31, 20.14s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 21 with global loss: 2.29 \n",
      "\n",
      "Beginning round 22\n",
      "\tWorker: 6032 \tlocal loss: 2.28\n",
      "\tWorker: 7904 \tlocal loss: 2.29\n",
      "\tWorker: 8440 \tlocal loss: 2.32\n",
      "\tWorker: 5680 \tlocal loss: 2.27\n",
      "\tWorker: 9656 \tlocal loss: 2.24\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.26\n",
      "\tWorker: 9976 \tlocal loss: 2.26\n",
      "\tWorker: 3760 \tlocal loss: 2.26\n",
      "\tWorker: 6616 \tlocal loss: 2.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 22%|██▏       | 22/100 [08:22<25:13, 19.40s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 22 with global loss: 2.29 \n",
      "\n",
      "Beginning round 23\n",
      "\tWorker: 6032 \tlocal loss: 2.28\n",
      "\tWorker: 7904 \tlocal loss: 2.28\n",
      "\tWorker: 8440 \tlocal loss: 2.32\n",
      "\tWorker: 5680 \tlocal loss: 2.28\n",
      "\tWorker: 9656 \tlocal loss: 2.24\n",
      "\tWorker: 3888 \tlocal loss: 2.26\n",
      "\tWorker: 1952 \tlocal loss: 2.25\n",
      "\tWorker: 9976 \tlocal loss: 2.24\n",
      "\tWorker: 3760 \tlocal loss: 2.26\n",
      "\tWorker: 6616 \tlocal loss: 2.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 23%|██▎       | 23/100 [08:40<24:21, 18.99s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 23 with global loss: 2.29 \n",
      "\n",
      "Beginning round 24\n",
      "\tWorker: 6032 \tlocal loss: 2.28\n",
      "\tWorker: 7904 \tlocal loss: 2.29\n",
      "\tWorker: 8440 \tlocal loss: 2.31\n",
      "\tWorker: 5680 \tlocal loss: 2.28\n",
      "\tWorker: 9656 \tlocal loss: 2.25\n",
      "\tWorker: 3888 \tlocal loss: 2.26\n",
      "\tWorker: 1952 \tlocal loss: 2.26\n",
      "\tWorker: 9976 \tlocal loss: 2.25\n",
      "\tWorker: 3760 \tlocal loss: 2.26\n",
      "\tWorker: 6616 \tlocal loss: 2.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 24%|██▍       | 24/100 [09:00<24:31, 19.36s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 24 with global loss: 2.29 \n",
      "\n",
      "Beginning round 25\n",
      "\tWorker: 6032 \tlocal loss: 2.28\n",
      "\tWorker: 7904 \tlocal loss: 2.28\n",
      "\tWorker: 8440 \tlocal loss: 2.31\n",
      "\tWorker: 5680 \tlocal loss: 2.28\n",
      "\tWorker: 9656 \tlocal loss: 2.25\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.26\n",
      "\tWorker: 9976 \tlocal loss: 2.25\n",
      "\tWorker: 3760 \tlocal loss: 2.25\n",
      "\tWorker: 6616 \tlocal loss: 2.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 25/100 [09:18<23:30, 18.81s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 25 with global loss: 2.29 \n",
      "\n",
      "Beginning round 26\n",
      "\tWorker: 6032 \tlocal loss: 2.28\n",
      "\tWorker: 7904 \tlocal loss: 2.28\n",
      "\tWorker: 8440 \tlocal loss: 2.31\n",
      "\tWorker: 5680 \tlocal loss: 2.27\n",
      "\tWorker: 9656 \tlocal loss: 2.25\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.26\n",
      "\tWorker: 9976 \tlocal loss: 2.25\n",
      "\tWorker: 3760 \tlocal loss: 2.25\n",
      "\tWorker: 6616 \tlocal loss: 2.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 26%|██▌       | 26/100 [09:40<24:33, 19.91s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 26 with global loss: 2.29 \n",
      "\n",
      "Beginning round 27\n",
      "\tWorker: 6032 \tlocal loss: 2.28\n",
      "\tWorker: 7904 \tlocal loss: 2.28\n",
      "\tWorker: 8440 \tlocal loss: 2.32\n",
      "\tWorker: 5680 \tlocal loss: 2.27\n",
      "\tWorker: 9656 \tlocal loss: 2.24\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.25\n",
      "\tWorker: 9976 \tlocal loss: 2.25\n",
      "\tWorker: 3760 \tlocal loss: 2.25\n",
      "\tWorker: 6616 \tlocal loss: 2.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 27%|██▋       | 27/100 [10:01<24:21, 20.03s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 27 with global loss: 2.29 \n",
      "\n",
      "Beginning round 28\n",
      "\tWorker: 6032 \tlocal loss: 2.27\n",
      "\tWorker: 7904 \tlocal loss: 2.28\n",
      "\tWorker: 8440 \tlocal loss: 2.32\n",
      "\tWorker: 5680 \tlocal loss: 2.28\n",
      "\tWorker: 9656 \tlocal loss: 2.24\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.25\n",
      "\tWorker: 9976 \tlocal loss: 2.24\n",
      "\tWorker: 3760 \tlocal loss: 2.26\n",
      "\tWorker: 6616 \tlocal loss: 2.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 28%|██▊       | 28/100 [10:20<23:48, 19.85s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 28 with global loss: 2.29 \n",
      "\n",
      "Beginning round 29\n",
      "\tWorker: 6032 \tlocal loss: 2.28\n",
      "\tWorker: 7904 \tlocal loss: 2.28\n",
      "\tWorker: 8440 \tlocal loss: 2.32\n",
      "\tWorker: 5680 \tlocal loss: 2.27\n",
      "\tWorker: 9656 \tlocal loss: 2.24\n",
      "\tWorker: 3888 \tlocal loss: 2.26\n",
      "\tWorker: 1952 \tlocal loss: 2.26\n",
      "\tWorker: 9976 \tlocal loss: 2.25\n",
      "\tWorker: 3760 \tlocal loss: 2.26\n",
      "\tWorker: 6616 \tlocal loss: 2.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 29%|██▉       | 29/100 [10:39<23:16, 19.68s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 29 with global loss: 2.29 \n",
      "\n",
      "Beginning round 30\n",
      "\tWorker: 6032 \tlocal loss: 2.27\n",
      "\tWorker: 7904 \tlocal loss: 2.27\n",
      "\tWorker: 8440 \tlocal loss: 2.32\n",
      "\tWorker: 5680 \tlocal loss: 2.28\n",
      "\tWorker: 9656 \tlocal loss: 2.24\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.26\n",
      "\tWorker: 9976 \tlocal loss: 2.24\n",
      "\tWorker: 3760 \tlocal loss: 2.26\n",
      "\tWorker: 6616 \tlocal loss: 2.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 30/100 [10:55<21:27, 18.39s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 30 with global loss: 2.29 \n",
      "\n",
      "Beginning round 31\n",
      "\tWorker: 6032 \tlocal loss: 2.28\n",
      "\tWorker: 7904 \tlocal loss: 2.27\n",
      "\tWorker: 8440 \tlocal loss: 2.31\n",
      "\tWorker: 5680 \tlocal loss: 2.27\n",
      "\tWorker: 9656 \tlocal loss: 2.23\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.25\n",
      "\tWorker: 9976 \tlocal loss: 2.25\n",
      "\tWorker: 3760 \tlocal loss: 2.26\n",
      "\tWorker: 6616 \tlocal loss: 2.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 31%|███       | 31/100 [11:11<20:30, 17.83s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 31 with global loss: 2.28 \n",
      "\n",
      "Beginning round 32\n",
      "\tWorker: 6032 \tlocal loss: 2.28\n",
      "\tWorker: 7904 \tlocal loss: 2.27\n",
      "\tWorker: 8440 \tlocal loss: 2.31\n",
      "\tWorker: 5680 \tlocal loss: 2.26\n",
      "\tWorker: 9656 \tlocal loss: 2.24\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.25\n",
      "\tWorker: 9976 \tlocal loss: 2.25\n",
      "\tWorker: 3760 \tlocal loss: 2.26\n",
      "\tWorker: 6616 \tlocal loss: 2.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 32%|███▏      | 32/100 [11:31<20:44, 18.30s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 32 with global loss: 2.28 \n",
      "\n",
      "Beginning round 33\n",
      "\tWorker: 6032 \tlocal loss: 2.27\n",
      "\tWorker: 7904 \tlocal loss: 2.27\n",
      "\tWorker: 8440 \tlocal loss: 2.31\n",
      "\tWorker: 5680 \tlocal loss: 2.27\n",
      "\tWorker: 9656 \tlocal loss: 2.24\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.26\n",
      "\tWorker: 9976 \tlocal loss: 2.25\n",
      "\tWorker: 3760 \tlocal loss: 2.25\n",
      "\tWorker: 6616 \tlocal loss: 2.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33%|███▎      | 33/100 [11:50<20:54, 18.73s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 33 with global loss: 2.28 \n",
      "\n",
      "Beginning round 34\n",
      "\tWorker: 6032 \tlocal loss: 2.28\n",
      "\tWorker: 7904 \tlocal loss: 2.26\n",
      "\tWorker: 8440 \tlocal loss: 2.31\n",
      "\tWorker: 5680 \tlocal loss: 2.27\n",
      "\tWorker: 9656 \tlocal loss: 2.24\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.25\n",
      "\tWorker: 9976 \tlocal loss: 2.24\n",
      "\tWorker: 3760 \tlocal loss: 2.26\n",
      "\tWorker: 6616 \tlocal loss: 2.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 34%|███▍      | 34/100 [12:10<20:57, 19.05s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 34 with global loss: 2.28 \n",
      "\n",
      "Beginning round 35\n",
      "\tWorker: 6032 \tlocal loss: 2.28\n",
      "\tWorker: 7904 \tlocal loss: 2.27\n",
      "\tWorker: 8440 \tlocal loss: 2.31\n",
      "\tWorker: 5680 \tlocal loss: 2.27\n",
      "\tWorker: 9656 \tlocal loss: 2.24\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.26\n",
      "\tWorker: 9976 \tlocal loss: 2.25\n",
      "\tWorker: 3760 \tlocal loss: 2.26\n",
      "\tWorker: 6616 \tlocal loss: 2.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▌      | 35/100 [12:36<22:51, 21.11s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 35 with global loss: 2.28 \n",
      "\n",
      "Beginning round 36\n",
      "\tWorker: 6032 \tlocal loss: 2.27\n",
      "\tWorker: 7904 \tlocal loss: 2.26\n",
      "\tWorker: 8440 \tlocal loss: 2.31\n",
      "\tWorker: 5680 \tlocal loss: 2.26\n",
      "\tWorker: 9656 \tlocal loss: 2.24\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.25\n",
      "\tWorker: 9976 \tlocal loss: 2.24\n",
      "\tWorker: 3760 \tlocal loss: 2.26\n",
      "\tWorker: 6616 \tlocal loss: 2.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 36%|███▌      | 36/100 [12:53<21:19, 19.99s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 36 with global loss: 2.28 \n",
      "\n",
      "Beginning round 37\n",
      "\tWorker: 6032 \tlocal loss: 2.27\n",
      "\tWorker: 7904 \tlocal loss: 2.26\n",
      "\tWorker: 8440 \tlocal loss: 2.31\n",
      "\tWorker: 5680 \tlocal loss: 2.27\n",
      "\tWorker: 9656 \tlocal loss: 2.24\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.25\n",
      "\tWorker: 9976 \tlocal loss: 2.24\n",
      "\tWorker: 3760 \tlocal loss: 2.25\n",
      "\tWorker: 6616 \tlocal loss: 2.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 37%|███▋      | 37/100 [13:12<20:30, 19.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 37 with global loss: 2.28 \n",
      "\n",
      "Beginning round 38\n",
      "\tWorker: 6032 \tlocal loss: 2.27\n",
      "\tWorker: 7904 \tlocal loss: 2.26\n",
      "\tWorker: 8440 \tlocal loss: 2.31\n",
      "\tWorker: 5680 \tlocal loss: 2.27\n",
      "\tWorker: 9656 \tlocal loss: 2.24\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.25\n",
      "\tWorker: 9976 \tlocal loss: 2.24\n",
      "\tWorker: 3760 \tlocal loss: 2.25\n",
      "\tWorker: 6616 \tlocal loss: 2.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 38%|███▊      | 38/100 [13:31<20:04, 19.43s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 38 with global loss: 2.28 \n",
      "\n",
      "Beginning round 39\n",
      "\tWorker: 6032 \tlocal loss: 2.27\n",
      "\tWorker: 7904 \tlocal loss: 2.25\n",
      "\tWorker: 8440 \tlocal loss: 2.31\n",
      "\tWorker: 5680 \tlocal loss: 2.27\n",
      "\tWorker: 9656 \tlocal loss: 2.24\n",
      "\tWorker: 3888 \tlocal loss: 2.26\n",
      "\tWorker: 1952 \tlocal loss: 2.25\n",
      "\tWorker: 9976 \tlocal loss: 2.24\n",
      "\tWorker: 3760 \tlocal loss: 2.25\n",
      "\tWorker: 6616 \tlocal loss: 2.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 39%|███▉      | 39/100 [13:52<20:12, 19.87s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 39 with global loss: 2.28 \n",
      "\n",
      "Beginning round 40\n",
      "\tWorker: 6032 \tlocal loss: 2.26\n",
      "\tWorker: 7904 \tlocal loss: 2.25\n",
      "\tWorker: 8440 \tlocal loss: 2.31\n",
      "\tWorker: 5680 \tlocal loss: 2.26\n",
      "\tWorker: 9656 \tlocal loss: 2.24\n",
      "\tWorker: 3888 \tlocal loss: 2.26\n",
      "\tWorker: 1952 \tlocal loss: 2.25\n",
      "\tWorker: 9976 \tlocal loss: 2.24\n",
      "\tWorker: 3760 \tlocal loss: 2.25\n",
      "\tWorker: 6616 \tlocal loss: 2.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 40/100 [14:14<20:32, 20.53s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 40 with global loss: 2.28 \n",
      "\n",
      "Beginning round 41\n",
      "\tWorker: 6032 \tlocal loss: 2.27\n",
      "\tWorker: 7904 \tlocal loss: 2.24\n",
      "\tWorker: 8440 \tlocal loss: 2.31\n",
      "\tWorker: 5680 \tlocal loss: 2.26\n",
      "\tWorker: 9656 \tlocal loss: 2.23\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.24\n",
      "\tWorker: 9976 \tlocal loss: 2.24\n",
      "\tWorker: 3760 \tlocal loss: 2.25\n",
      "\tWorker: 6616 \tlocal loss: 2.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 41%|████      | 41/100 [14:30<18:54, 19.24s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 41 with global loss: 2.28 \n",
      "\n",
      "Beginning round 42\n",
      "\tWorker: 6032 \tlocal loss: 2.27\n",
      "\tWorker: 7904 \tlocal loss: 2.25\n",
      "\tWorker: 8440 \tlocal loss: 2.31\n",
      "\tWorker: 5680 \tlocal loss: 2.26\n",
      "\tWorker: 9656 \tlocal loss: 2.23\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.24\n",
      "\tWorker: 9976 \tlocal loss: 2.23\n",
      "\tWorker: 3760 \tlocal loss: 2.26\n",
      "\tWorker: 6616 \tlocal loss: 2.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 42%|████▏     | 42/100 [14:47<17:54, 18.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 42 with global loss: 2.28 \n",
      "\n",
      "Beginning round 43\n",
      "\tWorker: 6032 \tlocal loss: 2.27\n",
      "\tWorker: 7904 \tlocal loss: 2.24\n",
      "\tWorker: 8440 \tlocal loss: 2.31\n",
      "\tWorker: 5680 \tlocal loss: 2.26\n",
      "\tWorker: 9656 \tlocal loss: 2.23\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.24\n",
      "\tWorker: 9976 \tlocal loss: 2.24\n",
      "\tWorker: 3760 \tlocal loss: 2.25\n",
      "\tWorker: 6616 \tlocal loss: 2.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 43%|████▎     | 43/100 [15:06<17:45, 18.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 43 with global loss: 2.28 \n",
      "\n",
      "Beginning round 44\n",
      "\tWorker: 6032 \tlocal loss: 2.27\n",
      "\tWorker: 7904 \tlocal loss: 2.24\n",
      "\tWorker: 8440 \tlocal loss: 2.31\n",
      "\tWorker: 5680 \tlocal loss: 2.26\n",
      "\tWorker: 9656 \tlocal loss: 2.23\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.25\n",
      "\tWorker: 9976 \tlocal loss: 2.23\n",
      "\tWorker: 3760 \tlocal loss: 2.26\n",
      "\tWorker: 6616 \tlocal loss: 2.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 44%|████▍     | 44/100 [15:22<16:43, 17.92s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 44 with global loss: 2.27 \n",
      "\n",
      "Beginning round 45\n",
      "\tWorker: 6032 \tlocal loss: 2.27\n",
      "\tWorker: 7904 \tlocal loss: 2.24\n",
      "\tWorker: 8440 \tlocal loss: 2.30\n",
      "\tWorker: 5680 \tlocal loss: 2.26\n",
      "\tWorker: 9656 \tlocal loss: 2.23\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.25\n",
      "\tWorker: 9976 \tlocal loss: 2.23\n",
      "\tWorker: 3760 \tlocal loss: 2.25\n",
      "\tWorker: 6616 \tlocal loss: 2.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|████▌     | 45/100 [15:41<16:37, 18.13s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 45 with global loss: 2.27 \n",
      "\n",
      "Beginning round 46\n",
      "\tWorker: 6032 \tlocal loss: 2.27\n",
      "\tWorker: 7904 \tlocal loss: 2.23\n",
      "\tWorker: 8440 \tlocal loss: 2.31\n",
      "\tWorker: 5680 \tlocal loss: 2.27\n",
      "\tWorker: 9656 \tlocal loss: 2.23\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.24\n",
      "\tWorker: 9976 \tlocal loss: 2.23\n",
      "\tWorker: 3760 \tlocal loss: 2.26\n",
      "\tWorker: 6616 \tlocal loss: 2.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 46%|████▌     | 46/100 [16:01<16:43, 18.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 46 with global loss: 2.27 \n",
      "\n",
      "Beginning round 47\n",
      "\tWorker: 6032 \tlocal loss: 2.27\n",
      "\tWorker: 7904 \tlocal loss: 2.23\n",
      "\tWorker: 8440 \tlocal loss: 2.31\n",
      "\tWorker: 5680 \tlocal loss: 2.25\n",
      "\tWorker: 9656 \tlocal loss: 2.24\n",
      "\tWorker: 3888 \tlocal loss: 2.26\n",
      "\tWorker: 1952 \tlocal loss: 2.24\n",
      "\tWorker: 9976 \tlocal loss: 2.23\n",
      "\tWorker: 3760 \tlocal loss: 2.26\n",
      "\tWorker: 6616 \tlocal loss: 2.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 47%|████▋     | 47/100 [16:22<17:10, 19.45s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 47 with global loss: 2.27 \n",
      "\n",
      "Beginning round 48\n",
      "\tWorker: 6032 \tlocal loss: 2.26\n",
      "\tWorker: 7904 \tlocal loss: 2.23\n",
      "\tWorker: 8440 \tlocal loss: 2.30\n",
      "\tWorker: 5680 \tlocal loss: 2.25\n",
      "\tWorker: 9656 \tlocal loss: 2.22\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.24\n",
      "\tWorker: 9976 \tlocal loss: 2.23\n",
      "\tWorker: 3760 \tlocal loss: 2.25\n",
      "\tWorker: 6616 \tlocal loss: 2.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 48%|████▊     | 48/100 [16:40<16:35, 19.15s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 48 with global loss: 2.27 \n",
      "\n",
      "Beginning round 49\n",
      "\tWorker: 6032 \tlocal loss: 2.27\n",
      "\tWorker: 7904 \tlocal loss: 2.24\n",
      "\tWorker: 8440 \tlocal loss: 2.31\n",
      "\tWorker: 5680 \tlocal loss: 2.26\n",
      "\tWorker: 9656 \tlocal loss: 2.24\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.24\n",
      "\tWorker: 9976 \tlocal loss: 2.23\n",
      "\tWorker: 3760 \tlocal loss: 2.25\n",
      "\tWorker: 6616 \tlocal loss: 2.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 49%|████▉     | 49/100 [17:01<16:39, 19.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 49 with global loss: 2.27 \n",
      "\n",
      "Beginning round 50\n",
      "\tWorker: 6032 \tlocal loss: 2.26\n",
      "\tWorker: 7904 \tlocal loss: 2.23\n",
      "\tWorker: 8440 \tlocal loss: 2.31\n",
      "\tWorker: 5680 \tlocal loss: 2.25\n",
      "\tWorker: 9656 \tlocal loss: 2.23\n",
      "\tWorker: 3888 \tlocal loss: 2.26\n",
      "\tWorker: 1952 \tlocal loss: 2.23\n",
      "\tWorker: 9976 \tlocal loss: 2.22\n",
      "\tWorker: 3760 \tlocal loss: 2.24\n",
      "\tWorker: 6616 \tlocal loss: 2.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 50/100 [17:19<15:51, 19.04s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 50 with global loss: 2.27 \n",
      "\n",
      "Beginning round 51\n",
      "\tWorker: 6032 \tlocal loss: 2.26\n",
      "\tWorker: 7904 \tlocal loss: 2.23\n",
      "\tWorker: 8440 \tlocal loss: 2.30\n",
      "\tWorker: 5680 \tlocal loss: 2.26\n",
      "\tWorker: 9656 \tlocal loss: 2.22\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.24\n",
      "\tWorker: 9976 \tlocal loss: 2.22\n",
      "\tWorker: 3760 \tlocal loss: 2.25\n",
      "\tWorker: 6616 \tlocal loss: 2.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 51%|█████     | 51/100 [17:35<14:54, 18.26s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 51 with global loss: 2.27 \n",
      "\n",
      "Beginning round 52\n",
      "\tWorker: 6032 \tlocal loss: 2.26\n",
      "\tWorker: 7904 \tlocal loss: 2.21\n",
      "\tWorker: 8440 \tlocal loss: 2.31\n",
      "\tWorker: 5680 \tlocal loss: 2.25\n",
      "\tWorker: 9656 \tlocal loss: 2.23\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.25\n",
      "\tWorker: 9976 \tlocal loss: 2.22\n",
      "\tWorker: 3760 \tlocal loss: 2.25\n",
      "\tWorker: 6616 \tlocal loss: 2.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 52%|█████▏    | 52/100 [17:52<14:15, 17.82s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 52 with global loss: 2.27 \n",
      "\n",
      "Beginning round 53\n",
      "\tWorker: 6032 \tlocal loss: 2.26\n",
      "\tWorker: 7904 \tlocal loss: 2.22\n",
      "\tWorker: 8440 \tlocal loss: 2.30\n",
      "\tWorker: 5680 \tlocal loss: 2.25\n",
      "\tWorker: 9656 \tlocal loss: 2.22\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.25\n",
      "\tWorker: 9976 \tlocal loss: 2.22\n",
      "\tWorker: 3760 \tlocal loss: 2.25\n",
      "\tWorker: 6616 \tlocal loss: 2.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 53%|█████▎    | 53/100 [18:12<14:24, 18.40s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 53 with global loss: 2.27 \n",
      "\n",
      "Beginning round 54\n",
      "\tWorker: 6032 \tlocal loss: 2.26\n",
      "\tWorker: 7904 \tlocal loss: 2.21\n",
      "\tWorker: 8440 \tlocal loss: 2.30\n",
      "\tWorker: 5680 \tlocal loss: 2.25\n",
      "\tWorker: 9656 \tlocal loss: 2.23\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.24\n",
      "\tWorker: 9976 \tlocal loss: 2.22\n",
      "\tWorker: 3760 \tlocal loss: 2.25\n",
      "\tWorker: 6616 \tlocal loss: 2.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 54%|█████▍    | 54/100 [18:28<13:39, 17.81s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 54 with global loss: 2.27 \n",
      "\n",
      "Beginning round 55\n",
      "\tWorker: 6032 \tlocal loss: 2.26\n",
      "\tWorker: 7904 \tlocal loss: 2.21\n",
      "\tWorker: 8440 \tlocal loss: 2.30\n",
      "\tWorker: 5680 \tlocal loss: 2.25\n",
      "\tWorker: 9656 \tlocal loss: 2.22\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.23\n",
      "\tWorker: 9976 \tlocal loss: 2.22\n",
      "\tWorker: 3760 \tlocal loss: 2.25\n",
      "\tWorker: 6616 \tlocal loss: 2.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 55%|█████▌    | 55/100 [18:46<13:21, 17.81s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 55 with global loss: 2.27 \n",
      "\n",
      "Beginning round 56\n",
      "\tWorker: 6032 \tlocal loss: 2.27\n",
      "\tWorker: 7904 \tlocal loss: 2.21\n",
      "\tWorker: 8440 \tlocal loss: 2.31\n",
      "\tWorker: 5680 \tlocal loss: 2.25\n",
      "\tWorker: 9656 \tlocal loss: 2.23\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.24\n",
      "\tWorker: 9976 \tlocal loss: 2.21\n",
      "\tWorker: 3760 \tlocal loss: 2.25\n",
      "\tWorker: 6616 \tlocal loss: 2.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 56%|█████▌    | 56/100 [19:06<13:29, 18.41s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 56 with global loss: 2.27 \n",
      "\n",
      "Beginning round 57\n",
      "\tWorker: 6032 \tlocal loss: 2.26\n",
      "\tWorker: 7904 \tlocal loss: 2.21\n",
      "\tWorker: 8440 \tlocal loss: 2.29\n",
      "\tWorker: 5680 \tlocal loss: 2.25\n",
      "\tWorker: 9656 \tlocal loss: 2.23\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.24\n",
      "\tWorker: 9976 \tlocal loss: 2.22\n",
      "\tWorker: 3760 \tlocal loss: 2.25\n",
      "\tWorker: 6616 \tlocal loss: 2.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 57%|█████▋    | 57/100 [19:23<12:58, 18.09s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 57 with global loss: 2.27 \n",
      "\n",
      "Beginning round 58\n",
      "\tWorker: 6032 \tlocal loss: 2.26\n",
      "\tWorker: 7904 \tlocal loss: 2.21\n",
      "\tWorker: 8440 \tlocal loss: 2.30\n",
      "\tWorker: 5680 \tlocal loss: 2.25\n",
      "\tWorker: 9656 \tlocal loss: 2.22\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.24\n",
      "\tWorker: 9976 \tlocal loss: 2.22\n",
      "\tWorker: 3760 \tlocal loss: 2.25\n",
      "\tWorker: 6616 \tlocal loss: 2.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 58%|█████▊    | 58/100 [19:41<12:31, 17.90s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 58 with global loss: 2.26 \n",
      "\n",
      "Beginning round 59\n",
      "\tWorker: 6032 \tlocal loss: 2.25\n",
      "\tWorker: 7904 \tlocal loss: 2.20\n",
      "\tWorker: 8440 \tlocal loss: 2.29\n",
      "\tWorker: 5680 \tlocal loss: 2.25\n",
      "\tWorker: 9656 \tlocal loss: 2.22\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.24\n",
      "\tWorker: 9976 \tlocal loss: 2.21\n",
      "\tWorker: 3760 \tlocal loss: 2.24\n",
      "\tWorker: 6616 \tlocal loss: 2.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 59%|█████▉    | 59/100 [20:00<12:28, 18.25s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 59 with global loss: 2.26 \n",
      "\n",
      "Beginning round 60\n",
      "\tWorker: 6032 \tlocal loss: 2.26\n",
      "\tWorker: 7904 \tlocal loss: 2.20\n",
      "\tWorker: 8440 \tlocal loss: 2.30\n",
      "\tWorker: 5680 \tlocal loss: 2.25\n",
      "\tWorker: 9656 \tlocal loss: 2.23\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.24\n",
      "\tWorker: 9976 \tlocal loss: 2.23\n",
      "\tWorker: 3760 \tlocal loss: 2.25\n",
      "\tWorker: 6616 \tlocal loss: 2.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 60/100 [20:20<12:29, 18.73s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 60 with global loss: 2.26 \n",
      "\n",
      "Beginning round 61\n",
      "\tWorker: 6032 \tlocal loss: 2.25\n",
      "\tWorker: 7904 \tlocal loss: 2.19\n",
      "\tWorker: 8440 \tlocal loss: 2.29\n",
      "\tWorker: 5680 \tlocal loss: 2.25\n",
      "\tWorker: 9656 \tlocal loss: 2.23\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.24\n",
      "\tWorker: 9976 \tlocal loss: 2.22\n",
      "\tWorker: 3760 \tlocal loss: 2.24\n",
      "\tWorker: 6616 \tlocal loss: 2.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 61%|██████    | 61/100 [20:36<11:48, 18.17s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 61 with global loss: 2.26 \n",
      "\n",
      "Beginning round 62\n",
      "\tWorker: 6032 \tlocal loss: 2.26\n",
      "\tWorker: 7904 \tlocal loss: 2.20\n",
      "\tWorker: 8440 \tlocal loss: 2.30\n",
      "\tWorker: 5680 \tlocal loss: 2.25\n",
      "\tWorker: 9656 \tlocal loss: 2.23\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.24\n",
      "\tWorker: 9976 \tlocal loss: 2.22\n",
      "\tWorker: 3760 \tlocal loss: 2.25\n",
      "\tWorker: 6616 \tlocal loss: 2.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 62%|██████▏   | 62/100 [20:55<11:39, 18.40s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 62 with global loss: 2.26 \n",
      "\n",
      "Beginning round 63\n",
      "\tWorker: 6032 \tlocal loss: 2.25\n",
      "\tWorker: 7904 \tlocal loss: 2.19\n",
      "\tWorker: 8440 \tlocal loss: 2.30\n",
      "\tWorker: 5680 \tlocal loss: 2.25\n",
      "\tWorker: 9656 \tlocal loss: 2.22\n",
      "\tWorker: 3888 \tlocal loss: 2.26\n",
      "\tWorker: 1952 \tlocal loss: 2.24\n",
      "\tWorker: 9976 \tlocal loss: 2.20\n",
      "\tWorker: 3760 \tlocal loss: 2.25\n",
      "\tWorker: 6616 \tlocal loss: 2.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 63%|██████▎   | 63/100 [21:14<11:18, 18.34s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 63 with global loss: 2.26 \n",
      "\n",
      "Beginning round 64\n",
      "\tWorker: 6032 \tlocal loss: 2.26\n",
      "\tWorker: 7904 \tlocal loss: 2.19\n",
      "\tWorker: 8440 \tlocal loss: 2.29\n",
      "\tWorker: 5680 \tlocal loss: 2.24\n",
      "\tWorker: 9656 \tlocal loss: 2.22\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.23\n",
      "\tWorker: 9976 \tlocal loss: 2.22\n",
      "\tWorker: 3760 \tlocal loss: 2.25\n",
      "\tWorker: 6616 \tlocal loss: 2.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 64%|██████▍   | 64/100 [21:30<10:40, 17.80s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 64 with global loss: 2.26 \n",
      "\n",
      "Beginning round 65\n",
      "\tWorker: 6032 \tlocal loss: 2.24\n",
      "\tWorker: 7904 \tlocal loss: 2.20\n",
      "\tWorker: 8440 \tlocal loss: 2.29\n",
      "\tWorker: 5680 \tlocal loss: 2.24\n",
      "\tWorker: 9656 \tlocal loss: 2.21\n",
      "\tWorker: 3888 \tlocal loss: 2.26\n",
      "\tWorker: 1952 \tlocal loss: 2.23\n",
      "\tWorker: 9976 \tlocal loss: 2.22\n",
      "\tWorker: 3760 \tlocal loss: 2.25\n",
      "\tWorker: 6616 \tlocal loss: 2.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|██████▌   | 65/100 [21:48<10:20, 17.72s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 65 with global loss: 2.26 \n",
      "\n",
      "Beginning round 66\n",
      "\tWorker: 6032 \tlocal loss: 2.25\n",
      "\tWorker: 7904 \tlocal loss: 2.20\n",
      "\tWorker: 8440 \tlocal loss: 2.30\n",
      "\tWorker: 5680 \tlocal loss: 2.25\n",
      "\tWorker: 9656 \tlocal loss: 2.22\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.24\n",
      "\tWorker: 9976 \tlocal loss: 2.21\n",
      "\tWorker: 3760 \tlocal loss: 2.25\n",
      "\tWorker: 6616 \tlocal loss: 2.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 66%|██████▌   | 66/100 [22:08<10:33, 18.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 66 with global loss: 2.26 \n",
      "\n",
      "Beginning round 67\n",
      "\tWorker: 6032 \tlocal loss: 2.26\n",
      "\tWorker: 7904 \tlocal loss: 2.18\n",
      "\tWorker: 8440 \tlocal loss: 2.30\n",
      "\tWorker: 5680 \tlocal loss: 2.25\n",
      "\tWorker: 9656 \tlocal loss: 2.22\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.23\n",
      "\tWorker: 9976 \tlocal loss: 2.21\n",
      "\tWorker: 3760 \tlocal loss: 2.23\n",
      "\tWorker: 6616 \tlocal loss: 2.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|██████▋   | 67/100 [22:26<10:00, 18.20s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 67 with global loss: 2.26 \n",
      "\n",
      "Beginning round 68\n",
      "\tWorker: 6032 \tlocal loss: 2.26\n",
      "\tWorker: 7904 \tlocal loss: 2.19\n",
      "\tWorker: 8440 \tlocal loss: 2.30\n",
      "\tWorker: 5680 \tlocal loss: 2.24\n",
      "\tWorker: 9656 \tlocal loss: 2.22\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.23\n",
      "\tWorker: 9976 \tlocal loss: 2.21\n",
      "\tWorker: 3760 \tlocal loss: 2.24\n",
      "\tWorker: 6616 \tlocal loss: 2.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 68%|██████▊   | 68/100 [22:43<09:39, 18.10s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 68 with global loss: 2.26 \n",
      "\n",
      "Beginning round 69\n",
      "\tWorker: 6032 \tlocal loss: 2.25\n",
      "\tWorker: 7904 \tlocal loss: 2.18\n",
      "\tWorker: 8440 \tlocal loss: 2.30\n",
      "\tWorker: 5680 \tlocal loss: 2.25\n",
      "\tWorker: 9656 \tlocal loss: 2.23\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.23\n",
      "\tWorker: 9976 \tlocal loss: 2.21\n",
      "\tWorker: 3760 \tlocal loss: 2.24\n",
      "\tWorker: 6616 \tlocal loss: 2.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 69%|██████▉   | 69/100 [23:04<09:46, 18.93s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 69 with global loss: 2.26 \n",
      "\n",
      "Beginning round 70\n",
      "\tWorker: 6032 \tlocal loss: 2.25\n",
      "\tWorker: 7904 \tlocal loss: 2.17\n",
      "\tWorker: 8440 \tlocal loss: 2.30\n",
      "\tWorker: 5680 \tlocal loss: 2.24\n",
      "\tWorker: 9656 \tlocal loss: 2.23\n",
      "\tWorker: 3888 \tlocal loss: 2.24\n",
      "\tWorker: 1952 \tlocal loss: 2.23\n",
      "\tWorker: 9976 \tlocal loss: 2.21\n",
      "\tWorker: 3760 \tlocal loss: 2.24\n",
      "\tWorker: 6616 \tlocal loss: 2.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|███████   | 70/100 [23:22<09:14, 18.49s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 70 with global loss: 2.26 \n",
      "\n",
      "Beginning round 71\n",
      "\tWorker: 6032 \tlocal loss: 2.24\n",
      "\tWorker: 7904 \tlocal loss: 2.19\n",
      "\tWorker: 8440 \tlocal loss: 2.29\n",
      "\tWorker: 5680 \tlocal loss: 2.24\n",
      "\tWorker: 9656 \tlocal loss: 2.23\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.23\n",
      "\tWorker: 9976 \tlocal loss: 2.21\n",
      "\tWorker: 3760 \tlocal loss: 2.24\n",
      "\tWorker: 6616 \tlocal loss: 2.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 71%|███████   | 71/100 [23:39<08:40, 17.95s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 71 with global loss: 2.26 \n",
      "\n",
      "Beginning round 72\n",
      "\tWorker: 6032 \tlocal loss: 2.25\n",
      "\tWorker: 7904 \tlocal loss: 2.17\n",
      "\tWorker: 8440 \tlocal loss: 2.29\n",
      "\tWorker: 5680 \tlocal loss: 2.25\n",
      "\tWorker: 9656 \tlocal loss: 2.21\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.24\n",
      "\tWorker: 9976 \tlocal loss: 2.19\n",
      "\tWorker: 3760 \tlocal loss: 2.24\n",
      "\tWorker: 6616 \tlocal loss: 2.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 72%|███████▏  | 72/100 [23:56<08:22, 17.94s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 72 with global loss: 2.25 \n",
      "\n",
      "Beginning round 73\n",
      "\tWorker: 6032 \tlocal loss: 2.25\n",
      "\tWorker: 7904 \tlocal loss: 2.17\n",
      "\tWorker: 8440 \tlocal loss: 2.30\n",
      "\tWorker: 5680 \tlocal loss: 2.24\n",
      "\tWorker: 9656 \tlocal loss: 2.23\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.23\n",
      "\tWorker: 9976 \tlocal loss: 2.21\n",
      "\tWorker: 3760 \tlocal loss: 2.24\n",
      "\tWorker: 6616 \tlocal loss: 2.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 73%|███████▎  | 73/100 [24:16<08:19, 18.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 73 with global loss: 2.25 \n",
      "\n",
      "Beginning round 74\n",
      "\tWorker: 6032 \tlocal loss: 2.25\n",
      "\tWorker: 7904 \tlocal loss: 2.17\n",
      "\tWorker: 8440 \tlocal loss: 2.30\n",
      "\tWorker: 5680 \tlocal loss: 2.24\n",
      "\tWorker: 9656 \tlocal loss: 2.22\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.22\n",
      "\tWorker: 9976 \tlocal loss: 2.22\n",
      "\tWorker: 3760 \tlocal loss: 2.24\n",
      "\tWorker: 6616 \tlocal loss: 2.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 74%|███████▍  | 74/100 [24:36<08:12, 18.93s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 74 with global loss: 2.25 \n",
      "\n",
      "Beginning round 75\n",
      "\tWorker: 6032 \tlocal loss: 2.25\n",
      "\tWorker: 7904 \tlocal loss: 2.16\n",
      "\tWorker: 8440 \tlocal loss: 2.29\n",
      "\tWorker: 5680 \tlocal loss: 2.24\n",
      "\tWorker: 9656 \tlocal loss: 2.21\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.23\n",
      "\tWorker: 9976 \tlocal loss: 2.20\n",
      "\tWorker: 3760 \tlocal loss: 2.24\n",
      "\tWorker: 6616 \tlocal loss: 2.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 75/100 [24:54<07:46, 18.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 75 with global loss: 2.25 \n",
      "\n",
      "Beginning round 76\n",
      "\tWorker: 6032 \tlocal loss: 2.25\n",
      "\tWorker: 7904 \tlocal loss: 2.18\n",
      "\tWorker: 8440 \tlocal loss: 2.29\n",
      "\tWorker: 5680 \tlocal loss: 2.24\n",
      "\tWorker: 9656 \tlocal loss: 2.22\n",
      "\tWorker: 3888 \tlocal loss: 2.24\n",
      "\tWorker: 1952 \tlocal loss: 2.22\n",
      "\tWorker: 9976 \tlocal loss: 2.20\n",
      "\tWorker: 3760 \tlocal loss: 2.24\n",
      "\tWorker: 6616 \tlocal loss: 2.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 76%|███████▌  | 76/100 [25:15<07:45, 19.41s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 76 with global loss: 2.25 \n",
      "\n",
      "Beginning round 77\n",
      "\tWorker: 6032 \tlocal loss: 2.24\n",
      "\tWorker: 7904 \tlocal loss: 2.17\n",
      "\tWorker: 8440 \tlocal loss: 2.30\n",
      "\tWorker: 5680 \tlocal loss: 2.24\n",
      "\tWorker: 9656 \tlocal loss: 2.22\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.22\n",
      "\tWorker: 9976 \tlocal loss: 2.20\n",
      "\tWorker: 3760 \tlocal loss: 2.24\n",
      "\tWorker: 6616 \tlocal loss: 2.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 77%|███████▋  | 77/100 [25:34<07:18, 19.06s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 77 with global loss: 2.25 \n",
      "\n",
      "Beginning round 78\n",
      "\tWorker: 6032 \tlocal loss: 2.25\n",
      "\tWorker: 7904 \tlocal loss: 2.18\n",
      "\tWorker: 8440 \tlocal loss: 2.29\n",
      "\tWorker: 5680 \tlocal loss: 2.23\n",
      "\tWorker: 9656 \tlocal loss: 2.21\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.23\n",
      "\tWorker: 9976 \tlocal loss: 2.19\n",
      "\tWorker: 3760 \tlocal loss: 2.23\n",
      "\tWorker: 6616 \tlocal loss: 2.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 78%|███████▊  | 78/100 [25:54<07:08, 19.48s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 78 with global loss: 2.25 \n",
      "\n",
      "Beginning round 79\n",
      "\tWorker: 6032 \tlocal loss: 2.25\n",
      "\tWorker: 7904 \tlocal loss: 2.16\n",
      "\tWorker: 8440 \tlocal loss: 2.29\n",
      "\tWorker: 5680 \tlocal loss: 2.22\n",
      "\tWorker: 9656 \tlocal loss: 2.21\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.22\n",
      "\tWorker: 9976 \tlocal loss: 2.20\n",
      "\tWorker: 3760 \tlocal loss: 2.24\n",
      "\tWorker: 6616 \tlocal loss: 2.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 79%|███████▉  | 79/100 [26:17<07:09, 20.48s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 79 with global loss: 2.25 \n",
      "\n",
      "Beginning round 80\n",
      "\tWorker: 6032 \tlocal loss: 2.25\n",
      "\tWorker: 7904 \tlocal loss: 2.17\n",
      "\tWorker: 8440 \tlocal loss: 2.28\n",
      "\tWorker: 5680 \tlocal loss: 2.23\n",
      "\tWorker: 9656 \tlocal loss: 2.21\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.23\n",
      "\tWorker: 9976 \tlocal loss: 2.19\n",
      "\tWorker: 3760 \tlocal loss: 2.23\n",
      "\tWorker: 6616 \tlocal loss: 2.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 80/100 [26:35<06:33, 19.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 80 with global loss: 2.25 \n",
      "\n",
      "Beginning round 81\n",
      "\tWorker: 6032 \tlocal loss: 2.24\n",
      "\tWorker: 7904 \tlocal loss: 2.15\n",
      "\tWorker: 8440 \tlocal loss: 2.29\n",
      "\tWorker: 5680 \tlocal loss: 2.23\n",
      "\tWorker: 9656 \tlocal loss: 2.22\n",
      "\tWorker: 3888 \tlocal loss: 2.26\n",
      "\tWorker: 1952 \tlocal loss: 2.23\n",
      "\tWorker: 9976 \tlocal loss: 2.19\n",
      "\tWorker: 3760 \tlocal loss: 2.23\n",
      "\tWorker: 6616 \tlocal loss: 2.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 81%|████████  | 81/100 [26:55<06:20, 20.01s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 81 with global loss: 2.25 \n",
      "\n",
      "Beginning round 82\n",
      "\tWorker: 6032 \tlocal loss: 2.25\n",
      "\tWorker: 7904 \tlocal loss: 2.14\n",
      "\tWorker: 8440 \tlocal loss: 2.29\n",
      "\tWorker: 5680 \tlocal loss: 2.22\n",
      "\tWorker: 9656 \tlocal loss: 2.21\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.23\n",
      "\tWorker: 9976 \tlocal loss: 2.20\n",
      "\tWorker: 3760 \tlocal loss: 2.24\n",
      "\tWorker: 6616 \tlocal loss: 2.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 82%|████████▏ | 82/100 [27:15<05:56, 19.79s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 82 with global loss: 2.25 \n",
      "\n",
      "Beginning round 83\n",
      "\tWorker: 6032 \tlocal loss: 2.24\n",
      "\tWorker: 7904 \tlocal loss: 2.17\n",
      "\tWorker: 8440 \tlocal loss: 2.28\n",
      "\tWorker: 5680 \tlocal loss: 2.22\n",
      "\tWorker: 9656 \tlocal loss: 2.22\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.23\n",
      "\tWorker: 9976 \tlocal loss: 2.18\n",
      "\tWorker: 3760 \tlocal loss: 2.24\n",
      "\tWorker: 6616 \tlocal loss: 2.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 83%|████████▎ | 83/100 [27:33<05:28, 19.30s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 83 with global loss: 2.25 \n",
      "\n",
      "Beginning round 84\n",
      "\tWorker: 6032 \tlocal loss: 2.24\n",
      "\tWorker: 7904 \tlocal loss: 2.16\n",
      "\tWorker: 8440 \tlocal loss: 2.29\n",
      "\tWorker: 5680 \tlocal loss: 2.23\n",
      "\tWorker: 9656 \tlocal loss: 2.21\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.22\n",
      "\tWorker: 9976 \tlocal loss: 2.19\n",
      "\tWorker: 3760 \tlocal loss: 2.24\n",
      "\tWorker: 6616 \tlocal loss: 2.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 84%|████████▍ | 84/100 [27:57<05:32, 20.78s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 84 with global loss: 2.25 \n",
      "\n",
      "Beginning round 85\n",
      "\tWorker: 6032 \tlocal loss: 2.24\n",
      "\tWorker: 7904 \tlocal loss: 2.15\n",
      "\tWorker: 8440 \tlocal loss: 2.29\n",
      "\tWorker: 5680 \tlocal loss: 2.23\n",
      "\tWorker: 9656 \tlocal loss: 2.21\n",
      "\tWorker: 3888 \tlocal loss: 2.24\n",
      "\tWorker: 1952 \tlocal loss: 2.22\n",
      "\tWorker: 9976 \tlocal loss: 2.20\n",
      "\tWorker: 3760 \tlocal loss: 2.23\n",
      "\tWorker: 6616 \tlocal loss: 2.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 85%|████████▌ | 85/100 [28:20<05:20, 21.40s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 85 with global loss: 2.24 \n",
      "\n",
      "Beginning round 86\n",
      "\tWorker: 6032 \tlocal loss: 2.24\n",
      "\tWorker: 7904 \tlocal loss: 2.17\n",
      "\tWorker: 8440 \tlocal loss: 2.28\n",
      "\tWorker: 5680 \tlocal loss: 2.23\n",
      "\tWorker: 9656 \tlocal loss: 2.21\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.21\n",
      "\tWorker: 9976 \tlocal loss: 2.20\n",
      "\tWorker: 3760 \tlocal loss: 2.24\n",
      "\tWorker: 6616 \tlocal loss: 2.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 86%|████████▌ | 86/100 [28:39<04:49, 20.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 86 with global loss: 2.24 \n",
      "\n",
      "Beginning round 87\n",
      "\tWorker: 6032 \tlocal loss: 2.24\n",
      "\tWorker: 7904 \tlocal loss: 2.14\n",
      "\tWorker: 8440 \tlocal loss: 2.29\n",
      "\tWorker: 5680 \tlocal loss: 2.23\n",
      "\tWorker: 9656 \tlocal loss: 2.22\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.22\n",
      "\tWorker: 9976 \tlocal loss: 2.18\n",
      "\tWorker: 3760 \tlocal loss: 2.23\n",
      "\tWorker: 6616 \tlocal loss: 2.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 87%|████████▋ | 87/100 [28:58<04:21, 20.09s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 87 with global loss: 2.24 \n",
      "\n",
      "Beginning round 88\n",
      "\tWorker: 6032 \tlocal loss: 2.24\n",
      "\tWorker: 7904 \tlocal loss: 2.14\n",
      "\tWorker: 8440 \tlocal loss: 2.29\n",
      "\tWorker: 5680 \tlocal loss: 2.22\n",
      "\tWorker: 9656 \tlocal loss: 2.21\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.22\n",
      "\tWorker: 9976 \tlocal loss: 2.19\n",
      "\tWorker: 3760 \tlocal loss: 2.23\n",
      "\tWorker: 6616 \tlocal loss: 2.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 88%|████████▊ | 88/100 [29:16<03:54, 19.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 88 with global loss: 2.24 \n",
      "\n",
      "Beginning round 89\n",
      "\tWorker: 6032 \tlocal loss: 2.23\n",
      "\tWorker: 7904 \tlocal loss: 2.12\n",
      "\tWorker: 8440 \tlocal loss: 2.28\n",
      "\tWorker: 5680 \tlocal loss: 2.23\n",
      "\tWorker: 9656 \tlocal loss: 2.20\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.22\n",
      "\tWorker: 9976 \tlocal loss: 2.19\n",
      "\tWorker: 3760 \tlocal loss: 2.24\n",
      "\tWorker: 6616 \tlocal loss: 2.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 89%|████████▉ | 89/100 [29:33<03:28, 18.93s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 89 with global loss: 2.24 \n",
      "\n",
      "Beginning round 90\n",
      "\tWorker: 6032 \tlocal loss: 2.22\n",
      "\tWorker: 7904 \tlocal loss: 2.14\n",
      "\tWorker: 8440 \tlocal loss: 2.27\n",
      "\tWorker: 5680 \tlocal loss: 2.22\n",
      "\tWorker: 9656 \tlocal loss: 2.20\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.22\n",
      "\tWorker: 9976 \tlocal loss: 2.18\n",
      "\tWorker: 3760 \tlocal loss: 2.23\n",
      "\tWorker: 6616 \tlocal loss: 2.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████ | 90/100 [29:51<03:04, 18.42s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 90 with global loss: 2.24 \n",
      "\n",
      "Beginning round 91\n",
      "\tWorker: 6032 \tlocal loss: 2.23\n",
      "\tWorker: 7904 \tlocal loss: 2.12\n",
      "\tWorker: 8440 \tlocal loss: 2.29\n",
      "\tWorker: 5680 \tlocal loss: 2.23\n",
      "\tWorker: 9656 \tlocal loss: 2.21\n",
      "\tWorker: 3888 \tlocal loss: 2.24\n",
      "\tWorker: 1952 \tlocal loss: 2.22\n",
      "\tWorker: 9976 \tlocal loss: 2.19\n",
      "\tWorker: 3760 \tlocal loss: 2.24\n",
      "\tWorker: 6616 \tlocal loss: 2.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 91%|█████████ | 91/100 [30:11<02:51, 19.08s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 91 with global loss: 2.24 \n",
      "\n",
      "Beginning round 92\n",
      "\tWorker: 6032 \tlocal loss: 2.23\n",
      "\tWorker: 7904 \tlocal loss: 2.14\n",
      "\tWorker: 8440 \tlocal loss: 2.28\n",
      "\tWorker: 5680 \tlocal loss: 2.22\n",
      "\tWorker: 9656 \tlocal loss: 2.21\n",
      "\tWorker: 3888 \tlocal loss: 2.24\n",
      "\tWorker: 1952 \tlocal loss: 2.21\n",
      "\tWorker: 9976 \tlocal loss: 2.18\n",
      "\tWorker: 3760 \tlocal loss: 2.24\n",
      "\tWorker: 6616 \tlocal loss: 2.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 92%|█████████▏| 92/100 [30:28<02:26, 18.25s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 92 with global loss: 2.24 \n",
      "\n",
      "Beginning round 93\n",
      "\tWorker: 6032 \tlocal loss: 2.23\n",
      "\tWorker: 7904 \tlocal loss: 2.12\n",
      "\tWorker: 8440 \tlocal loss: 2.28\n",
      "\tWorker: 5680 \tlocal loss: 2.22\n",
      "\tWorker: 9656 \tlocal loss: 2.20\n",
      "\tWorker: 3888 \tlocal loss: 2.24\n",
      "\tWorker: 1952 \tlocal loss: 2.22\n",
      "\tWorker: 9976 \tlocal loss: 2.20\n",
      "\tWorker: 3760 \tlocal loss: 2.24\n",
      "\tWorker: 6616 \tlocal loss: 2.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 93%|█████████▎| 93/100 [30:45<02:05, 17.86s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 93 with global loss: 2.24 \n",
      "\n",
      "Beginning round 94\n",
      "\tWorker: 6032 \tlocal loss: 2.23\n",
      "\tWorker: 7904 \tlocal loss: 2.13\n",
      "\tWorker: 8440 \tlocal loss: 2.27\n",
      "\tWorker: 5680 \tlocal loss: 2.23\n",
      "\tWorker: 9656 \tlocal loss: 2.21\n",
      "\tWorker: 3888 \tlocal loss: 2.24\n",
      "\tWorker: 1952 \tlocal loss: 2.21\n",
      "\tWorker: 9976 \tlocal loss: 2.18\n",
      "\tWorker: 3760 \tlocal loss: 2.23\n",
      "\tWorker: 6616 \tlocal loss: 2.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 94%|█████████▍| 94/100 [31:01<01:44, 17.45s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 94 with global loss: 2.24 \n",
      "\n",
      "Beginning round 95\n",
      "\tWorker: 6032 \tlocal loss: 2.23\n",
      "\tWorker: 7904 \tlocal loss: 2.12\n",
      "\tWorker: 8440 \tlocal loss: 2.28\n",
      "\tWorker: 5680 \tlocal loss: 2.23\n",
      "\tWorker: 9656 \tlocal loss: 2.22\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.21\n",
      "\tWorker: 9976 \tlocal loss: 2.19\n",
      "\tWorker: 3760 \tlocal loss: 2.21\n",
      "\tWorker: 6616 \tlocal loss: 2.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 95%|█████████▌| 95/100 [31:18<01:26, 17.33s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 95 with global loss: 2.24 \n",
      "\n",
      "Beginning round 96\n",
      "\tWorker: 6032 \tlocal loss: 2.25\n",
      "\tWorker: 7904 \tlocal loss: 2.11\n",
      "\tWorker: 8440 \tlocal loss: 2.27\n",
      "\tWorker: 5680 \tlocal loss: 2.21\n",
      "\tWorker: 9656 \tlocal loss: 2.21\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.22\n",
      "\tWorker: 9976 \tlocal loss: 2.18\n",
      "\tWorker: 3760 \tlocal loss: 2.22\n",
      "\tWorker: 6616 \tlocal loss: 2.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 96%|█████████▌| 96/100 [31:35<01:08, 17.11s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 96 with global loss: 2.24 \n",
      "\n",
      "Beginning round 97\n",
      "\tWorker: 6032 \tlocal loss: 2.23\n",
      "\tWorker: 7904 \tlocal loss: 2.12\n",
      "\tWorker: 8440 \tlocal loss: 2.27\n",
      "\tWorker: 5680 \tlocal loss: 2.22\n",
      "\tWorker: 9656 \tlocal loss: 2.20\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.21\n",
      "\tWorker: 9976 \tlocal loss: 2.19\n",
      "\tWorker: 3760 \tlocal loss: 2.23\n",
      "\tWorker: 6616 \tlocal loss: 2.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 97%|█████████▋| 97/100 [31:51<00:50, 16.99s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 97 with global loss: 2.24 \n",
      "\n",
      "Beginning round 98\n",
      "\tWorker: 6032 \tlocal loss: 2.23\n",
      "\tWorker: 7904 \tlocal loss: 2.10\n",
      "\tWorker: 8440 \tlocal loss: 2.28\n",
      "\tWorker: 5680 \tlocal loss: 2.22\n",
      "\tWorker: 9656 \tlocal loss: 2.20\n",
      "\tWorker: 3888 \tlocal loss: 2.25\n",
      "\tWorker: 1952 \tlocal loss: 2.22\n",
      "\tWorker: 9976 \tlocal loss: 2.19\n",
      "\tWorker: 3760 \tlocal loss: 2.24\n",
      "\tWorker: 6616 \tlocal loss: 2.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 98%|█████████▊| 98/100 [32:11<00:35, 17.85s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 98 with global loss: 2.23 \n",
      "\n",
      "Beginning round 99\n",
      "\tWorker: 6032 \tlocal loss: 2.22\n",
      "\tWorker: 7904 \tlocal loss: 2.12\n",
      "\tWorker: 8440 \tlocal loss: 2.28\n",
      "\tWorker: 5680 \tlocal loss: 2.21\n",
      "\tWorker: 9656 \tlocal loss: 2.21\n",
      "\tWorker: 3888 \tlocal loss: 2.24\n",
      "\tWorker: 1952 \tlocal loss: 2.21\n",
      "\tWorker: 9976 \tlocal loss: 2.17\n",
      "\tWorker: 3760 \tlocal loss: 2.23\n",
      "\tWorker: 6616 \tlocal loss: 2.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 99%|█████████▉| 99/100 [32:26<00:16, 16.87s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 99 with global loss: 2.23 \n",
      "\n",
      "Beginning round 100\n",
      "\tWorker: 6032 \tlocal loss: 2.22\n",
      "\tWorker: 7904 \tlocal loss: 2.11\n",
      "\tWorker: 8440 \tlocal loss: 2.28\n",
      "\tWorker: 5680 \tlocal loss: 2.22\n",
      "\tWorker: 9656 \tlocal loss: 2.20\n",
      "\tWorker: 3888 \tlocal loss: 2.24\n",
      "\tWorker: 1952 \tlocal loss: 2.21\n",
      "\tWorker: 9976 \tlocal loss: 2.18\n",
      "\tWorker: 3760 \tlocal loss: 2.23\n",
      "\tWorker: 6616 \tlocal loss: 2.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 100/100 [32:43<00:00, 16.81s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round 100 with global loss: 2.23 \n",
      "\n",
      "Federated Training Time: 1963.02\n"
     ]
    }
   ],
   "source": [
    "print(\"Training\", num_rounds, \"round(s) with\", manager.n_workers, \"worker(s) doing\", num_epochs, \"epoch(s) per round.\\n\" )\n",
    "\n",
    "training_start_time = time.time()\n",
    "\n",
    "for i in tqdm(range(num_rounds)):\n",
    "    print(\"Beginning round\", i+1)\n",
    "    manager.round()\n",
    "    print(\"Finished round\", i+1, \"with global loss: %.2f\" % manager.manager_loss_history[-1], \"\\n\")\n",
    "\n",
    "run_data['Federated Training Time'] = time.time() - training_start_time\n",
    "#run_data['Manager Loss History'] = manager.manager_loss_history\n",
    "#run_data['Worker Loss Histories'] = manager.worker_loss_histories\n",
    "run_data['Final Global Loss'] = manager.manager_loss_history[-1]\n",
    "\n",
    "print('Federated Training Time: %.2f' % run_data['Federated Training Time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look at how the training went. Here's a graph of the loss per round."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 9))\n",
    "# loss of global model on test set gets recorded twice per round\n",
    "# [1::2] skips the record that takes place before that round's training has happened\n",
    "ax.plot(manager.manager_loss_history[1::2], label=\"Global Loss\", )\n",
    "ax.set_xlabel(\"Federated Round\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks pretty good, with loss dropping off just like we want. Perhaps it's a little bumpy because of the relatively fast training rate, but it should be improving on balance. But if we look under the hood at each individual worker's loss, we see that the workers' local models are diverging and converging at each round. They diverge because each local model trains on different data, resulting in a somewhat different loss per round. The converge again because the manager combines them into a master model, such that they all have the same loss as the global loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 9))\n",
    "\n",
    "\n",
    "for i in range(len(manager.worker_loss_histories)):\n",
    "    ax.plot(manager.worker_loss_histories[i], label=('Worker ' + str(i)))\n",
    "\n",
    "# TODO: Align the global loss properly\n",
    "ax.plot(manager.manager_loss_history[1], label=\"Global Loss\", )\n",
    "\n",
    "    \n",
    "# TODO: Get these labels done properly - they should be aligned with the main \n",
    "ax.set_xticklabels([(i-1) for i in range(len(manager.worker_loss_histories))])\n",
    "ax.set_xlabel(\"Federated Round\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Write a bit of code that records the hyperparameters and saves the graphs, times and losses in a bundle for each run. Something like:\n",
    "\n",
    "```\n",
    "2019-05-06 21:02:50\n",
    "\n",
    "# standard dataloader parameter\n",
    "batch_size = 128\n",
    "\n",
    "# biasing parameters\n",
    "skew_bias = 0.3\n",
    "loader_size = 8192\n",
    "num_workers = 10\n",
    "\n",
    "Stacked set creation time: 00:01:08\n",
    "\n",
    "# training parameters\n",
    "learning_rate = 1e-2\n",
    "num_epochs = 1\n",
    "num_rounds = 20\n",
    "\n",
    "Train time = 00:43:02\n",
    "\n",
    "Final global loss: 0.48251\n",
    "```\n",
    "\n",
    "Well. I did this. And now the code is unreadable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outline:\n",
    "- Set up a model and data\n",
    "- train the model N epochs without federation note baseline performance (and size of the data that would have to have been transferedd?) \n",
    "    - is this model trained on the full dataset? Or do we sample randomly across it to have the same number of examples?\n",
    "- Federate without skew or mild skew, compare performance with baseline (and size of model compared to data)\n",
    "- Federate with only a few numbers skewed (like, lacking only 7s or something) \n",
    "- Federate with heavy skew\n",
    "- Federate with complete skew\n",
    "\n",
    "Ideas:\n",
    "- plot performance on a given numeral for the main model next to that of a worker skewed against that numeral. Let both run without federation or run a few epochs before federation. Show this as a baseline\n",
    "- histogram of numerals? More for curiosity, but shows spread of data that we might want to reflect in the baseline training.\n",
    "- post 1: what's the accuracy loss for federation compared to baseline direct training?\n",
    "- post 2: weird side stats\n",
    "    - skew vs. accuracy\n",
    "        - plot - x-axis = skew, y-axis = accuracy\n",
    "    - run all to convergence, compare how long to reach comparable accuracy?\n",
    "        - time or epochs necessary to reach comparable accuracy between federated and standard approach\n",
    "        - time or epochs necessary to reach comparable accuracy by skew\n",
    "    - \n",
    "\n",
    "Questions:\n",
    "- Why does the time spent by a worker on any given epoch all happen _before_ the batches start rolling in? What's happening there? Am I just spinning my wheels on something?\n",
    "    - TODO: try this from a regular python file. The notebook may be buffering up those print statements in the batches\n",
    "- Why does random selection of the skewed datasets take so long? Is it because they're without replacement?\n",
    "- Why do all the workers and epochs always happen in order? Wouldn't my laptop parallelize them across cores? Is that too much to ask from an interpreter? Is the interpreter smarter than I am and actually is parallelizing them and the smartest way in to do them in order?\n",
    "- why use ten workers? Why not fewer?\n",
    "\n",
    "- TODO: unequal data volume at each worker. Try some workers with very small or very large samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# a little performance info on the run\n",
    "run_data['Global End Time'] = time.time()\n",
    "run_data['Global Time'] = run_data['Global End Time'] - run_data['Global Start Time']\n",
    "run_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leave a record of the run\n",
    "# but it isn't valid JSON\n",
    "import json \n",
    "with open('run_data.json', 'a') as file:\n",
    "    file.write(json.dumps(run_data))\n",
    "    file.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "train_counts = Counter(int(y) for y in train_dset.targets).most_common()\n",
    "print(\"Train digit counts: \\n\", train_counts)\n",
    "print(\"Train count standard deviation: %.2f\" % np.std(list(zip(*train_counts))[1]))\n",
    "print(\"Train count coefficient of variation: %.2f\" \n",
    "      % (float(np.mean(list(zip(*train_counts))[1])) / float(np.std(list(zip(*train_counts))[1]))))\n",
    "\n",
    "print()\n",
    "\n",
    "test_counts = Counter(int(y) for y in test_dset.targets).most_common()\n",
    "print(\"Test digit counts: \\n\", test_counts)\n",
    "print(\"Test standard deviation: %.2f\" % np.std(list(zip(*test_counts))[1]))\n",
    "print(\"Test count coefficient of variation: %.2f\" \n",
    "      % (float(np.mean(list(zip(*test_counts))[1])) / float(np.std(list(zip(*test_counts))[1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "fig.suptitle('Digit Counts at each Worker')\n",
    "ax.xaxis.set_major_locator(plt.MultipleLocator(1))\n",
    "ax.set_xticklabels([('Digit ' + str(x-1)) for x in range(11)])\n",
    "ax.hist(hist_counts, \n",
    "        label=[('Worker ' + str(x)) for x in range(num_workers)],\n",
    "        bins=list(range(12)), \n",
    "        histtype='bar',\n",
    "        align='left',\n",
    "        rwidth=0.8,\n",
    "       );\n",
    "ax.legend();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
